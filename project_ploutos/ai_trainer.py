# ai_trainer.py
# ---------------------------------------------------------
# ENTRA√éNEUR IA "IRON MAN TURBO" - RTX 3060 OPTIMIZED
# ---------------------------------------------------------
import pandas as pd
import numpy as np
import os
import torch
import sys
import shutil
from datetime import datetime

# --- W&B INTEGRATION ---
try:
    import wandb
    from wandb.integration.sb3 import WandbCallback
    USE_WANDB = True
    print("üìä Monitoring W&B : ACTIV√â")
except ImportError:
    USE_WANDB = False
    print("‚ö†Ô∏è W&B non install√©. Fallback sur TensorBoard.")

# --- ARCHITECTURES ---
try:
    from sb3_contrib import RecurrentPPO
    USE_LSTM = True
    print("üß† Architecture : LSTM (Recurrent Neural Network)")
except ImportError:
    from stable_baselines3 import PPO
    USE_LSTM = False
    print("üß† Architecture : MLP (Standard)")

from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv, VecNormalize
from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback
from trading_env import StockTradingEnv
from trading_bot import TradingBrain

# ============================================
# üéÆ CONFIGURATION GPU & HARDWARE
# ============================================
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"\n{'='*60}")
print(f"üéÆ Device: {device.upper()}")
if device == "cuda":
    print(f"   GPU: {torch.cuda.get_device_name(0)}")
    print(f"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    print(f"   Compute Capability: {torch.cuda.get_device_properties(0).major}.{torch.cuda.get_device_properties(0).minor}")
    torch.backends.cudnn.benchmark = True  # Optimisation CUDA
print(f"{'='*60}\n")

# Exploitation multi-c≈ìurs Ryzen 7 9800X3D
torch.set_num_threads(8)
os.environ['OMP_NUM_THREADS'] = '8'

# ============================================
# üìä CONFIGURATION ENTRA√éNEMENT
# ============================================
MODEL_FILE = "ppo_trading_brain"
PROJECT_NAME = "Ploutos_Trading_V40_GPU"

# SECTEURS USINE
SECTORS = {
    "TECH": ["NVDA", "AAPL", "MSFT", "AMD", "TSLA", "QQQ", "META", "GOOGL"],
    "DEFENSIVE": ["KO", "PG", "JNJ", "MCD", "WMT", "XLV", "CVS", "PFE"],
    "ENERGY": ["XOM", "CVX", "SLB", "XLE", "CAT", "OXY", "COP"],
    "CRYPTO": ["COIN", "MSTR", "MARA", "BITO", "RIOT", "CLSK"]
}

# Gestion Arguments CLI
TRAINING_TICKERS = ["SPY", "NVDA", "JPM", "XOM", "GLD", "TSLA", "AMZN", "GOOGL"]
if len(sys.argv) > 1:
    arg = sys.argv[1].upper()
    if arg in SECTORS:
        print(f"üè≠ CIBLE SECTORIELLE : {arg}")
        TRAINING_TICKERS = SECTORS[arg]
        MODEL_FILE = f"brain_{arg.lower()}"

# Hyperparam√®tres AGRESSIFS (optimis√©s pour RTX 3060)
EPOCHS = 10                    # Cycles d'entra√Ænement complets
TOTAL_TIMESTEPS = 500000       # Steps par ticker (3.3x plus qu'avant)
N_ENVS = 8                     # Environnements parall√®les (1 par c≈ìur CPU)
EVAL_FREQ = 10000              # Fr√©quence d'√©valuation
SAVE_FREQ = 50000              # Fr√©quence de sauvegarde checkpoints

# Cache global des donn√©es
DATA_CACHE = {}

# ============================================
# üì¶ PR√âCHARGEMENT DONN√âES EN RAM
# ============================================
def precompute_all_data():
    """Charge toutes les donn√©es en RAM pour √©viter I/O pendant l'entra√Ænement"""
    print(f"\nüíæ [{MODEL_FILE}] Pr√©chargement des donn√©es en RAM...")
    brain = TradingBrain()
    
    for i, ticker in enumerate(TRAINING_TICKERS, 1):
        print(f"   [{i}/{len(TRAINING_TICKERS)}] T√©l√©chargement {ticker}...", end=" ")
        df = brain.telecharger_donnees(ticker)
        
        if df is None or df.empty:
            print("‚ùå ERREUR")
            continue
        
        df = df.copy()
        close = df['Close']
        
        # Calcul Indicateurs Techniques
        # RSI
        delta = close.diff()
        gain = (delta.where(delta > 0, 0)).rolling(14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
        rs = gain / loss.replace(0, 0.001)
        df['RSI'] = 100 - (100 / (1 + rs))
        
        # SMA Ratio
        df['SMA_Ratio'] = close / close.rolling(50).mean()
        
        # MACD
        e1 = close.ewm(span=12).mean()
        e2 = close.ewm(span=26).mean()
        df['MACD'] = e1 - e2
        
        # Volatilit√©
        df['Volatility'] = close.rolling(20).std() / close.rolling(20).mean()
        
        # Volume normalis√©
        df['Volume_Norm'] = df['Volume'] / df['Volume'].rolling(20).mean()
        
        DATA_CACHE[ticker] = df.dropna().reset_index(drop=True)
        print(f"‚úÖ {len(df)} lignes")
    
    print(f"\n‚úÖ {len(DATA_CACHE)} tickers charg√©s ({sum(len(v) for v in DATA_CACHE.values())} lignes totales)\n")

# ============================================
# üèóÔ∏è FACTORY D'ENVIRONNEMENTS
# ============================================
def make_env(ticker, rank=0):
    """Cr√©e un environnement de trading pour un ticker donn√©"""
    def _init():
        df = DATA_CACHE.get(ticker, pd.DataFrame())
        if df.empty:
            raise ValueError(f"Pas de donn√©es pour {ticker}")
        
        env = StockTradingEnv(df)
        env.seed(42 + rank)
        return env
    
    return _init

# ============================================
# üéØ FONCTION PRINCIPALE D'ENTRA√éNEMENT
# ============================================
def train_model():
    """Entra√Æne le mod√®le avec environnements parall√®les et GPU"""
    
    # Pr√©chargement
    precompute_all_data()
    if not DATA_CACHE:
        print("‚ùå Aucune donn√©e charg√©e. Arr√™t.")
        return
    
    print(f"üöÄ D√©marrage Entra√Ænement : {MODEL_FILE}")
    print(f"   ‚Ä¢ Device: {device}")
    print(f"   ‚Ä¢ Epochs: {EPOCHS}")
    print(f"   ‚Ä¢ Steps/ticker: {TOTAL_TIMESTEPS:,}")
    print(f"   ‚Ä¢ Environnements parall√®les: {N_ENVS}")
    
    # Nettoyage fichiers locaux
    for ext in [".zip", "_vecnorm.pkl"]:
        filepath = MODEL_FILE + ext
        if os.path.exists(filepath):
            os.remove(filepath)
            print(f"üóëÔ∏è  Suppression ancien {filepath}")
    
    # Configuration Architecture selon LSTM ou MLP
    if USE_LSTM:
        policy_kwargs = dict(
            lstm_hidden_size=512,        # Taille LSTM augment√©e
            n_lstm_layers=2,             # 2 couches LSTM empil√©es
            enable_critic_lstm=True,
            shared_lstm=False,
            net_arch=[512, 512]          # Couches denses apr√®s LSTM
        )
        AlgoClass = RecurrentPPO
        policy_type = "MlpLstmPolicy"
        batch_size = 2048                # Optimis√© pour 12GB VRAM
        n_steps = 8192
        n_epochs_ppo = 10
    else:
        policy_kwargs = dict(
            net_arch=dict(
                pi=[1024, 1024, 512, 256],  # Policy network profond
                vf=[1024, 1024, 512, 256]   # Value network profond
            ),
            activation_fn=torch.nn.ReLU
        )
        AlgoClass = PPO
        policy_type = "MlpPolicy"
        batch_size = 4096                # Gros batch pour GPU
        n_steps = 8192
        n_epochs_ppo = 10
    
    print(f"\nüìê Architecture:")
    print(f"   ‚Ä¢ Type: {policy_type}")
    print(f"   ‚Ä¢ Batch Size: {batch_size}")
    print(f"   ‚Ä¢ N Steps: {n_steps}")
    print(f"   ‚Ä¢ PPO Epochs: {n_epochs_ppo}\n")
    
    model = None
    start_time = datetime.now()
    
    # ============================================
    # üîÑ BOUCLE D'ENTRA√éNEMENT MULTI-EPOCHS
    # ============================================
    for epoch in range(EPOCHS):
        print(f"\n{'='*60}")
        print(f"üîÑ {MODEL_FILE} - EPOCH {epoch+1}/{EPOCHS}")
        print(f"{'='*60}\n")
        
        for ticker_idx, ticker in enumerate(TRAINING_TICKERS, 1):
            if ticker not in DATA_CACHE:
                print(f"‚ö†Ô∏è  Skipping {ticker} (no data)")
                continue
            
            print(f"\nüìà [{ticker_idx}/{len(TRAINING_TICKERS)}] Training on {ticker}...")
            
            # --- CR√âATION ENVIRONNEMENTS PARALL√àLES ---
            # Utilise SubprocVecEnv pour vrai parall√©lisme (multiprocessing)
            env_fns = [make_env(ticker, rank=i) for i in range(N_ENVS)]
            
            if N_ENVS > 1:
                base_env = SubprocVecEnv(env_fns)
            else:
                base_env = DummyVecEnv(env_fns)
            
            # Normalisation (critique pour la stabilit√©)
            norm_env = VecNormalize(
                base_env,
                norm_obs=True,
                norm_reward=True,
                clip_obs=10.0,
                clip_reward=10.0,
                gamma=0.99
            )
            
            # --- INITIALISATION W&B ---
            if USE_WANDB:
                run = wandb.init(
                    project=PROJECT_NAME,
                    group=MODEL_FILE,
                    name=f"{ticker}_Ep{epoch+1}",
                    config={
                        "policy_type": policy_type,
                        "device": device,
                        "total_timesteps": TOTAL_TIMESTEPS,
                        "ticker": ticker,
                        "epoch": epoch + 1,
                        "n_envs": N_ENVS,
                        "batch_size": batch_size,
                        "n_steps": n_steps,
                        "learning_rate": 3e-4
                    },
                    reinit=True,
                    sync_tensorboard=True,
                    monitor_gym=True
                )
                tensorboard_log = f"./runs/{run.id}"
            else:
                tensorboard_log = f"./logs/{MODEL_FILE}"
            
            # --- CR√âATION / UPDATE MOD√àLE ---
            if model is None:
                print(f"üèóÔ∏è  Cr√©ation du mod√®le initial...")
                model = AlgoClass(
                    policy_type,
                    norm_env,
                    verbose=1,
                    device=device,
                    learning_rate=3e-4,
                    n_steps=n_steps,
                    batch_size=batch_size,
                    n_epochs=n_epochs_ppo,
                    gamma=0.99,
                    gae_lambda=0.95,
                    clip_range=0.2,
                    clip_range_vf=None,
                    ent_coef=0.01,              # Encourage exploration
                    vf_coef=0.5,
                    max_grad_norm=0.5,
                    policy_kwargs=policy_kwargs,
                    tensorboard_log=tensorboard_log
                )
            else:
                print(f"üîÑ Mise √† jour environnement du mod√®le...")
                model.set_env(norm_env)
            
            # --- CALLBACKS ---
            callbacks = []
            
            # Checkpoint r√©guliers
            checkpoint_callback = CheckpointCallback(
                save_freq=SAVE_FREQ,
                save_path=f"./checkpoints/{MODEL_FILE}/",
                name_prefix=f"{ticker}_ep{epoch}"
            )
            callbacks.append(checkpoint_callback)
            
            # W&B Callback
            if USE_WANDB:
                wandb_callback = WandbCallback(
                    gradient_save_freq=100,
                    model_save_path=f"models/{run.id}",
                    verbose=2
                )
                callbacks.append(wandb_callback)
            
            # --- ENTRA√éNEMENT ---
            print(f"üéì Apprentissage {TOTAL_TIMESTEPS:,} steps...")
            model.learn(
                total_timesteps=TOTAL_TIMESTEPS,
                callback=callbacks,
                reset_num_timesteps=False,  # Continue l'apprentissage
                progress_bar=True
            )
            
            # --- SAUVEGARDE ---
            print(f"üíæ Sauvegarde du mod√®le...")
            model.save(MODEL_FILE)
            norm_env.save(MODEL_FILE + "_vecnorm.pkl")
            
            # Fermeture W&B
            if USE_WANDB:
                run.finish()
            
            # Nettoyage environnement
            norm_env.close()
            
            elapsed = datetime.now() - start_time
            print(f"‚è±Ô∏è  Temps √©coul√©: {elapsed}")
    
    # ============================================
    # ‚úÖ FIN DE L'ENTRA√éNEMENT
    # ============================================
    total_time = datetime.now() - start_time
    print(f"\n{'='*60}")
    print(f"‚úÖ ENTRA√éNEMENT TERMIN√â")
    print(f"{'='*60}")
    print(f"üìä Statistiques:")
    print(f"   ‚Ä¢ Dur√©e totale: {total_time}")
    print(f"   ‚Ä¢ Mod√®le: {MODEL_FILE}.zip")
    print(f"   ‚Ä¢ Normalisation: {MODEL_FILE}_vecnorm.pkl")
    print(f"   ‚Ä¢ Epochs: {EPOCHS}")
    print(f"   ‚Ä¢ Tickers: {len(TRAINING_TICKERS)}")
    print(f"   ‚Ä¢ Steps totaux: {EPOCHS * len(TRAINING_TICKERS) * TOTAL_TIMESTEPS:,}")
    print(f"{'='*60}\n")

# ============================================
# üöÄ POINT D'ENTR√âE
# ============================================
if __name__ == "__main__":
    try:
        train_model()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Entra√Ænement interrompu par l'utilisateur")
    except Exception as e:
        print(f"\n‚ùå ERREUR: {e}")
        import traceback
        traceback.print_exc()
