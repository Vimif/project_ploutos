# Ploutos Developer Knowledge & Troubleshooting

Ce document consigne les le√ßons apprises, les probl√®mes techniques r√©solus et les optimisations sp√©cifiques √† ce projet. √Ä lire avant toute modification majeure.

---

## 1. Donn√©es Historiques (1h Timeframe)

### Probl√®me : Limite Yahoo Finance
- **Limite** : Yahoo Finance ne fournit que **730 jours (2 ans)** d'historique pour les donn√©es horaires (`1h`).
- **Cons√©quence** : Impossible d'entra√Æner un mod√®le robuste sur 5 ans avec Yahoo seul.

### Solution : Alpaca + Local Dataset
- Utiliser l'API **Alpaca** (Paper ou Live) qui offre **5+ ans** d'historique en `1h`.
- Script : `scripts/build_dataset.py` t√©l√©charge tout en CSV dans `data/dataset_v8/`.
- Config : `training_config_v8.yaml` -> `dataset_path: ./data/dataset_v8/`.
- **R√®gle d'Or** : Toujours utiliser le dataset local pour l'entra√Ænement intensif. Ne plus t√©l√©charger √† la vol√©e.

---

## 2. Conflits de Timezones (Pandas)

### Probl√®me : `TypeError: Cannot compare dtypes datetime64[s] and datetime64[us, UTC]`
- **Cause** : 
    - Donn√©es Alpaca (Local Dataset) sont en **UTC** (tz-aware).
    - Donn√©es Macro (Yahoo) sont souvent **na√Øves** (tz-naive) ou vice-versa.
    - Lors du `reindex` dans `core/macro_data.py`, Pandas crashe.

### Solution : Alignement Automatique
- Dans `core/macro_data.py` -> `align_to_ticker()`.
- Le code d√©tecte la timezone du ticker cible et convertit la macro pour qu'elle corresponde (soit `tz_localize('UTC')`, soit `tz_localize(None)`).

---

## 3. Optimisation Hardware (RunPod / Serveurs D√©di√©s)

### Contexte : Machine "Monstre" (256 Cores, 1TB RAM, RTX 3090)
Les param√®tres par d√©faut de `stable-baselines3` sous-utilisent massivement ce genre de hardware (10-20% de charge).

### Param√®tres "Turbo" (dans `config/hardware.py`)
Pour saturer la machine et acc√©l√©rer l'entra√Ænement :
- **n_envs** : Monter √† **256** (1 env par CPU core).
- **batch_size** : Monter √† **65536** (pour remplir les 24GB VRAM de la 3090).
- **n_steps** : Monter √† **4096** (r√©duit l'overhead CPU/GPU).
- **Ensemble** : Lancer 10 ou 20 mod√®les en parall√®le (`--ensemble 20`).

### Risques
- **Latence de d√©marrage** : Initialiser 256 environnements prend du temps (1-2 minutes).

### üö® Thread Explosion (OpenBLAS / MKL)
- **Sympt√¥me** : `OpenBLAS blas_thread_init: pthread_create failed`, `Resource temporarily unavailable`, `BrokenPipeError`.
- **Cause** : Si on lance 256 processus (`n_envs`) et que chaque processus lance 128 threads (OpenBLAS par d√©faut), on atteint **32 768 threads**. Linux tue le programme.
- **Solution** : Forcer 1 thread par processus via variables d'env :
  ```bash
  export OMP_NUM_THREADS=1
  export MKL_NUM_THREADS=1
  export OPENBLAS_NUM_THREADS=1
  ```
- **Script** : Utiliser `./start_training.sh` qui configure tout cela automatiquement.

### üö® RAM Limitation (116 GB)
- **Sympt√¥me** : Crash "Out Of Memory" (OOM) au d√©marrage des 256 environnements.
- **Cause** : Chaque env consomme ~400Mo. 256 * 400Mo = ~100Go + Syst√®me = Saturation.
- **Solution** : Le script `config/hardware.py` limite d√©sormais automatiquement `n_envs` √† **~90-128** si < 128GB RAM d√©tect√©s.

---

## 4. Strat√©gie Walk-Forward & Overfitting

### Constat (F√©vrier 2026)
- Entra√Æner sur 1 an -> Overfitting massif (25% pertes en Monte Carlo).
- Le mod√®le "apprend par c≈ìur" le bruit de march√©.

### Correction
- **Fen√™tre d'entra√Ænement** : Minimum **5 ans** (`train_years: 5`).
- **Simplicite** : Reseau `[256, 128]` au lieu de `[512, 512, 512]` (meilleur ratio parametres/samples).
- **Moins d'al√©atoire** : `ent_coef` r√©duit √† `0.01` (vs 0.05).
- **Ensemble Learning** : Toujours utiliser plusieurs mod√®les (`--ensemble 5+`) pour lisser la variance.

---

## 5. Optimisation : "Turbo Init" (Pre-computed Features)

### Probl√®me : D√©marrage Lent des Environnements
- Avec `n_envs=256`, chaque processus calcule ind√©pendamment les indicateurs techniques (RSI, MACD, etc.) pour 15 tickers sur 50 000 bougies.
- **Co√ªt** : 256 processus x 15 tickers x 50k bougies = **192 Millions de calculs** au d√©marrage.
- **R√©sultat** : CPU √† 100% pendant des minutes, risque de timeout ou crash.

### Solution : Calcul par Fold & Partage
- **V9.1** : `training/train.py` calcule les features **par fold** (pas sur tout le dataset) pour eviter le look-ahead bias.
- **Injection** : Les DataFrames enrichis sont passes aux environnements avec le flag `features_precomputed=True`.
- **Environnement** : `TradingEnv` detecte le flag et **saute** le calcul interne.
- **Gain** : Demarrage quasi-instantane des 256 environnements (juste copie memoire).

---

## 6. M√©thodologie Institutionnelle (V8.1 - F√©vrier 2026)

### üõ°Ô∏è Embargo (Anti-Leak)
- **Probl√®me** : Les indicateurs techniques (ex: EMA 200, RSI 14) "regardent en arri√®re". Si le Test Set commence imm√©diatement apr√®s le Train Set, les premi√®res 200 bougies de Test contiennent de l'information d√©j√† vue par le Train (Data Leakage).
- **Solution** : `training/train.py` impose un **Embargo** (gap) de 1 mois entre la fin du Train et le d√©but du Test.
- **Impact** : Performance Test l√©g√®rement moins bonne MAIS beaucoup plus r√©aliste.

### Differential Sharpe Ratio (DSR)
- **Probleme** : Recompenser le Profit ($) incite a la prise de risque excessive (gambling).
- **Solution** : `core/reward_calculator.py` implemente le **DSR** avec l'algorithme de **Welford** pour la variance online (ref: Moody & Saffell, 2001).
- **Principe** : L'agent est recompense si son action augmente le Sharpe Ratio glissant (Risk-Adjusted Return) plutot que le PnL brut.
- **Stabilite** : Welford evite l'explosion numerique quand `std(returns) ‚âà 0` (marche plat). Floor de variance a `1e-4`.

### Hyperparametres PPO "Investisseur"
- **GAE Lambda** : Augmente a **0.98** (vs 0.95) pour favoriser les tendances long terme et reduire le bruit.
- **Overtrading Penalty** : Doublee (`0.01`) pour punir severement le "churning" (achat/vente inutile).
- **Trade Success Reward** : Reduite (`0.2`) pour ne pas biaiser l'agent vers des strategies a haut taux de reussite mais faible gain moyen.

---

## 7. Divergence SHM / Raw Data Path (V9.1 - Fevrier 2026)

### Probleme : Train/Test Feature Set Mismatch
- **Symptome** : `TypeError: float() argument must be a string or a real number, not 'Timestamp'` lors de `evaluate_on_test`.
- **Cause racine** : Le chemin training (SharedMemory) et le chemin test (DataFrames bruts) produisaient des feature sets differents.
  - SHM : `select_dtypes(include=[np.number]).astype(float32)` homogeneise tous les types numeriques (int32 -> float32).
  - Raw : le filtre dtype `(np.float64, np.float32, np.int64)` excluait les colonnes `int32` produites par Polars `cast(pl.Int32)` (~25 features binaires).
- **Fix** : Remplacer le filtre explicite par `pd.api.types.is_numeric_dtype()` dans `_prepare_features()`.

### Probleme : Polars Index Round-Trip
- **Symptome** : Colonne datetime residuelle dans le DataFrame apres conversion Polars -> Pandas.
- **Cause** : Le nom d'index varie ('Date', 'Datetime', None) et la logique de restauration `set_index('date')` est case-sensitive.
- **Fix** : Normaliser l'index en `__date_idx` avant conversion, restaurer apres.

### Regle d'Or
Toujours verifier la parite entre le chemin SHM (training) et le chemin raw (test). Si le test crash mais le training fonctionne, le probleme est probablement une divergence dtype.

---

## 8. Tests & Mocking (V9.1 - Fevrier 2026)

### Mocking torch/SB3 dans les tests
- Mocker TOUS les sous-modules torch : `torch.nn`, `torch.nn.functional`, `torch.optim`, `torch.utils`, `torch.utils.data`, `torch.distributions`.
- Aussi : `stable_baselines3`, `stable_baselines3.common`, `stable_baselines3.common.vec_env`, etc.
- **NE PAS** mettre le mock torch dans `conftest.py` ‚Äî ca casse les tests e2e qui ont besoin du vrai torch.
- `isinstance()` crashe si le 2e argument est un MagicMock (pas un type) ‚Äî utiliser `HAS_RECURRENT=False` + `patch.object()`.

### Tests de look-ahead bias
- **NE PAS** generer deux datasets separes avec `np.random.seed(42)` ‚Äî l'etat RNG diverge apres des generations de longueurs differentes.
- Generer UN seul dataset long, le decouper pour la version courte : `df_short = df_long.iloc[:200].copy()`.

