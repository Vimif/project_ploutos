# Ploutos Developer Knowledge & Troubleshooting

Ce document consigne les le√ßons apprises, les probl√®mes techniques r√©solus et les optimisations sp√©cifiques √† ce projet. √Ä lire avant toute modification majeure.

---

## 1. Donn√©es Historiques (1h Timeframe)

### Probl√®me : Limite Yahoo Finance
- **Limite** : Yahoo Finance ne fournit que **730 jours (2 ans)** d'historique pour les donn√©es horaires (`1h`).
- **Cons√©quence** : Impossible d'entra√Æner un mod√®le robuste sur 5 ans avec Yahoo seul.

### Solution : Alpaca + Local Dataset
- Utiliser l'API **Alpaca** (Paper ou Live) qui offre **5+ ans** d'historique en `1h`.
- Script : `scripts/build_dataset.py` t√©l√©charge tout en CSV dans `data/dataset_v8/`.
- Config : `training_config_v8.yaml` -> `dataset_path: ./data/dataset_v8/`.
- **R√®gle d'Or** : Toujours utiliser le dataset local pour l'entra√Ænement intensif. Ne plus t√©l√©charger √† la vol√©e.

---

## 2. Conflits de Timezones (Pandas)

### Probl√®me : `TypeError: Cannot compare dtypes datetime64[s] and datetime64[us, UTC]`
- **Cause** : 
    - Donn√©es Alpaca (Local Dataset) sont en **UTC** (tz-aware).
    - Donn√©es Macro (Yahoo) sont souvent **na√Øves** (tz-naive) ou vice-versa.
    - Lors du `reindex` dans `core/macro_data.py`, Pandas crashe.

### Solution : Alignement Automatique
- Dans `core/macro_data.py` -> `align_to_ticker()`.
- Le code d√©tecte la timezone du ticker cible et convertit la macro pour qu'elle corresponde (soit `tz_localize('UTC')`, soit `tz_localize(None)`).

---

## 3. Optimisation Hardware (RunPod / Serveurs D√©di√©s)

### Contexte : Machine "Monstre" (256 Cores, 1TB RAM, RTX 3090)
Les param√®tres par d√©faut de `stable-baselines3` sous-utilisent massivement ce genre de hardware (10-20% de charge).

### Param√®tres "Turbo" (dans `config/hardware.py`)
Pour saturer la machine et acc√©l√©rer l'entra√Ænement :
- **n_envs** : Monter √† **256** (1 env par CPU core).
- **batch_size** : Monter √† **65536** (pour remplir les 24GB VRAM de la 3090).
- **n_steps** : Monter √† **4096** (r√©duit l'overhead CPU/GPU).
- **Ensemble** : Lancer 10 ou 20 mod√®les en parall√®le (`--ensemble 20`).

### Risques
- **Latence de d√©marrage** : Initialiser 256 environnements prend du temps (1-2 minutes).

### üö® Thread Explosion (OpenBLAS / MKL)
- **Sympt√¥me** : `OpenBLAS blas_thread_init: pthread_create failed`, `Resource temporarily unavailable`, `BrokenPipeError`.
- **Cause** : Si on lance 256 processus (`n_envs`) et que chaque processus lance 128 threads (OpenBLAS par d√©faut), on atteint **32 768 threads**. Linux tue le programme.
- **Solution** : Forcer 1 thread par processus via variables d'env :
  ```bash
  export OMP_NUM_THREADS=1
  export MKL_NUM_THREADS=1
  export OPENBLAS_NUM_THREADS=1
  ```
- **Script** : Utiliser `./start_training.sh` qui configure tout cela automatiquement.

---

- **Script** : Utiliser `./start_training.sh` qui configure tout cela automatiquement.

---

## 4. Strat√©gie Walk-Forward & Overfitting

### Constat (F√©vrier 2026)
- Entra√Æner sur 1 an -> Overfitting massif (25% pertes en Monte Carlo).
- Le mod√®le "apprend par c≈ìur" le bruit de march√©.

### Correction
- **Fen√™tre d'entra√Ænement** : Minimum **5 ans** (`train_years: 5`).
- **Simplicit√©** : R√©seau de neurones plus large mais moins profond (`[512, 512, 512]` au lieu de 4 couches).
- **Moins d'al√©atoire** : `ent_coef` r√©duit √† `0.01` (vs 0.05).
- **Ensemble Learning** : Toujours utiliser plusieurs mod√®les (`--ensemble 5+`) pour lisser la variance.

---

## 5. Optimisation : "Turbo Init" (Pre-computed Features)

### Probl√®me : D√©marrage Lent des Environnements
- Avec `n_envs=256`, chaque processus calcule ind√©pendamment les indicateurs techniques (RSI, MACD, etc.) pour 15 tickers sur 50 000 bougies.
- **Co√ªt** : 256 processus x 15 tickers x 50k bougies = **192 Millions de calculs** au d√©marrage.
- **R√©sultat** : CPU √† 100% pendant des minutes, risque de timeout ou crash.

### Solution : Calcul Unique & Partage
- **Modification** : `training/train_walk_forward.py` calcule les features **une seule fois** au d√©but (dans le processus principal).
- **Injection** : Les DataFrames enrichis sont pass√©s aux environnements avec le flag `features_precomputed=True`.
- **Environnement** : `UniversalTradingEnvV8LSTM` d√©tecte le flag et **saute** le calcul interne.
- **Gain** : D√©marrage quasi-instantan√© des 256 environnements (juste copie m√©moire).

