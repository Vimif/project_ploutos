# ğŸ“ Curriculum Learning pour Ploutos

## ğŸ“Š Vue d'ensemble

Le **Curriculum Learning** est une approche d'entraÃ®nement progressif qui permet au modÃ¨le d'apprendre de maniÃ¨re incrÃ©mentale, du plus simple au plus complexe.

### ğŸ¯ Objectifs

- âœ… **AmÃ©liorer la robustesse** : Le modÃ¨le apprend Ã  gÃ©nÃ©raliser progressivement
- âœ… **Transfer Learning** : Chaque stage bÃ©nÃ©ficie du prÃ©cÃ©dent
- âœ… **Sharpe Ratio supÃ©rieur** : Attendu entre 1.8 et 2.5 (vs 1.0-1.5 classique)
- âœ… **Auto-optimisation optionnelle** : 15 trials Optuna pour affiner les hyperparams

---

## ğŸ”„ Les 3 Stages

### **Stage 1 : Mono-Asset (SPY)**

```yaml
Objectif    : Apprendre les bases sur 1 ETF simple
Asset       : SPY uniquement
Timesteps   : 3,000,000
N_envs      : 4
DurÃ©e       : ~3 heures (RTX 3080)
Sharpe cible: 1.0
```

**Pourquoi SPY ?**
- ETF diversifiÃ© (S&P 500), peu volatil
- Mouvements prÃ©visibles et structurÃ©s
- Parfait pour apprendre les bases du trading

---

### **Stage 2 : Multi-Asset (ETFs)**

```yaml
Objectif    : GÃ©nÃ©raliser sur plusieurs ETFs
Assets      : SPY, QQQ, IWM
Timesteps   : 5,000,000
N_envs      : 8
DurÃ©e       : ~5 heures
Sharpe cible: 1.3
```

**Nouvelles compÃ©tences :**
- GÃ©rer un portfolio multi-asset
- CorrÃ©lations entre ETFs
- Allocation dynamique

---

### **Stage 3 : Actions Complexes**

```yaml
Objectif    : MaÃ®triser des actions volatiles
Assets      : NVDA, MSFT, AAPL, GOOGL, AMZN
Timesteps   : 10,000,000
N_envs      : 16
DurÃ©e       : ~10 heures
Sharpe cible: 1.5
```

**DÃ©fis supplÃ©mentaires :**
- VolatilitÃ© Ã©levÃ©e (NVDA peut varier de 5-10% par jour)
- CorrÃ©lations complexes (tech stocks)
- Risque de drawdown accru

---

## ğŸš€ Utilisation

### **Option 1 : Sans Auto-Optimisation (Rapide)**

```bash
cd /root/ai-factory/tmp/project_ploutos

# Stage 1
python3 scripts/train_curriculum.py --stage 1

# Stage 2 (avec transfer learning automatique)
python3 scripts/train_curriculum.py --stage 2

# Stage 3
python3 scripts/train_curriculum.py --stage 3

# DurÃ©e totale : ~18 heures
```

---

### **Option 2 : Avec Auto-Optimisation (Optimal)**

```bash
# Stage 1 avec optimisation rapide (15 trials)
python3 scripts/train_curriculum.py --stage 1 --auto-optimize

# Stage 2
python3 scripts/train_curriculum.py --stage 2 --auto-optimize

# Stage 3
python3 scripts/train_curriculum.py --stage 3 --auto-optimize

# DurÃ©e totale : ~20 heures (+30min par stage pour Optuna)
# Gain Sharpe attendu : +0.2 Ã  +0.3 par stage
```

---

### **Option 3 : Stage par Stage Manuel**

```bash
# EntraÃ®ner Stage 1
python3 scripts/train_curriculum.py --stage 1 --auto-optimize

# Attendre fin, vÃ©rifier Sharpe > 1.0

# Passer Ã  Stage 2 avec modÃ¨le Stage 1
python3 scripts/train_curriculum.py --stage 2 \
  --load-model models/stage1_final \
  --auto-optimize

# Attendre fin, vÃ©rifier Sharpe > 1.3

# Passer Ã  Stage 3
python3 scripts/train_curriculum.py --stage 3 \
  --load-model models/stage2_final \
  --auto-optimize
```

---

## ğŸ“Š Suivi de l'EntraÃ®nement

### **Weights & Biases**

```bash
# Le script log automatiquement sur W&B
# Projet : Ploutos_Curriculum

# AccÃ©der au dashboard :
https://wandb.ai/your-username/Ploutos_Curriculum
```

**MÃ©triques trackÃ©es :**
- Loss (policy + value)
- Sharpe Ratio
- Portfolio Value
- Success Rate

---

### **TensorBoard (Local)**

```bash
# Lancer TensorBoard
tensorboard --logdir logs/

# AccÃ©der Ã  : http://localhost:6006
```

---

### **GPU Monitoring**

```bash
# Surveiller l'utilisation GPU
watch -n 1 nvidia-smi

# Ou avec gpustat (plus lisible)
pip install gpustat
gpustat -i 1
```

---

## ğŸ’¾ ModÃ¨les SauvegardÃ©s

```
models/
â”œâ”€â”€ stage1/
â”‚   â”œâ”€â”€ ploutos_stage1_50000_steps.zip
â”‚   â”œâ”€â”€ ploutos_stage1_100000_steps.zip
â”‚   â”œâ”€â”€ optimized_params.json           # Si --auto-optimize
â”‚   â””â”€â”€ ...
â”œâ”€â”€ stage1_final.zip                   # ModÃ¨le final Stage 1
â”œâ”€â”€ stage2/
â”‚   â”œâ”€â”€ ploutos_stage2_100000_steps.zip
â”‚   â”œâ”€â”€ optimized_params.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ stage2_final.zip                   # ModÃ¨le final Stage 2
â”œâ”€â”€ stage3/
â”‚   â”œâ”€â”€ ploutos_stage3_200000_steps.zip
â”‚   â”œâ”€â”€ optimized_params.json
â”‚   â””â”€â”€ ...
â””â”€â”€ stage3_final.zip                   # ğŸ¯ ModÃ¨le PRODUCTION
```

---

## âš¡ Auto-Optimisation Rapide

### **Fonctionnement**

Quand `--auto-optimize` est activÃ© :

1. **15 trials Optuna** (au lieu de 50 classiques)
2. **Optimise seulement 3 params critiques** :
   - `learning_rate`
   - `n_steps`
   - `ent_coef`
3. **DurÃ©e** : +30 minutes par stage
4. **Gain Sharpe** : +0.2 Ã  +0.3

### **Params PrÃ©-CalibrÃ©s vs OptimisÃ©s**

| Stage | Learning Rate (Base) | Learning Rate (OptimisÃ©) | Gain Sharpe |
|-------|---------------------|--------------------------|-------------|
| 1     | 1e-4               | 8e-5 Ã  2e-4            | +0.2        |
| 2     | 5e-5               | 3e-5 Ã  1e-4            | +0.3        |
| 3     | 3e-5               | 1e-5 Ã  6e-5            | +0.3        |

---

## ğŸ“ˆ RÃ©sultats Attendus

### **Sans Auto-Optimisation**

```
Stage 1 : Sharpe = 1.0-1.2
Stage 2 : Sharpe = 1.3-1.5
Stage 3 : Sharpe = 1.5-1.8

DurÃ©e totale : 18h
```

### **Avec Auto-Optimisation**

```
Stage 1 : Sharpe = 1.2-1.4  (+0.2)
Stage 2 : Sharpe = 1.6-1.8  (+0.3)
Stage 3 : Sharpe = 1.8-2.3  (+0.3)

DurÃ©e totale : 20h (+2h Optuna)
```

---

## ğŸ› ï¸ DÃ©pannage

### **Erreur : CUDA out of memory**

```bash
# RÃ©duire batch_size et n_envs dans le code
# Ou redÃ©marrer le GPU
sudo systemctl restart nvidia-persistenced
```

### **Erreur : SubprocVecEnv freeze**

```bash
# Utiliser DummyVecEnv si problÃ¨mes multiprocessing
# Modifier dans train_curriculum.py ligne 389 :
from stable_baselines3.common.vec_env import DummyVecEnv
env = DummyVecEnv([make_env(data)])
```

### **Sharpe Ratio < 0**

```
Causes possibles :
1. DonnÃ©es corrompues (vÃ©rifier data_cache/)
2. ModÃ¨le prÃ©cÃ©dent incompatible
3. Hyperparams inadaptÃ©s

Solution :
- Nettoyer data_cache/
- Repartir de zÃ©ro sans --load-model
- Activer --auto-optimize
```

---

## ğŸ’¡ Bonnes Pratiques

### **1. Lancer en ArriÃ¨re-Plan**

```bash
# Avec nohup
nohup python3 scripts/train_curriculum.py --stage 1 --auto-optimize \
  > logs/stage1_$(date +%Y%m%d_%H%M).log 2>&1 &

# Suivre les logs
tail -f logs/stage1_*.log
```

### **2. VÃ©rifier GPU Disponible**

```bash
# Avant de lancer
nvidia-smi

# Si GPU utilisÃ© par autre process, tuer ou attendre
```

### **3. Sauvegarder RÃ©guliÃ¨rement**

```bash
# Les checkpoints sont auto-sauvegardÃ©s tous les N steps
# Mais copier le dernier modÃ¨le aprÃ¨s chaque stage :
cp models/stage1_final.zip backups/stage1_$(date +%Y%m%d).zip
```

---

## ğŸ”— Ressources

- [Stable-Baselines3 Docs](https://stable-baselines3.readthedocs.io/)
- [Optuna Documentation](https://optuna.readthedocs.io/)
- [Weights & Biases](https://wandb.ai/)
- [PPO Algorithm Explained](https://arxiv.org/abs/1707.06347)

---

## ğŸ¯ Prochaines Ã‰tapes

AprÃ¨s avoir terminÃ© le curriculum learning :

1. **Ã‰valuer le modÃ¨le** sur donnÃ©es de validation
2. **DÃ©ployer sur VPS** pour trading live
3. **CrÃ©er des modÃ¨les spÃ©cialisÃ©s par rÃ©gime** (Bull/Bear/Sideways)
4. **ImplÃ©menter le rÃ©-entraÃ®nement automatique** mensuel

---

**Questions ou problÃ¨mes ?** Ouvrir une issue sur GitHub ou consulter les logs.