#!/usr/bin/env python3
"""
Performance Monitor Callback
Surveille FPS, GPU, CPU en temps r√©el et d√©tecte bottlenecks
"""

import time
import numpy as np
import wandb
from stable_baselines3.common.callbacks import BaseCallback
from collections import deque

try:
    import psutil
    HAS_PSUTIL = True
except ImportError:
    HAS_PSUTIL = False

try:
    import pynvml
    pynvml.nvmlInit()
    HAS_NVML = True
except:
    HAS_NVML = False

class PerformanceMonitor(BaseCallback):
    """
    Surveille performance et d√©tecte bottlenecks
    """
    
    def __init__(self, log_freq=5000, verbose=1):
        """
        Args:
            log_freq: Fr√©quence de log (en steps)
            verbose: Niveau de verbosit√©
        """
        super().__init__(verbose)
        
        self.log_freq = log_freq
        self.last_log_step = 0
        
        # Buffers
        self.fps_buffer = deque(maxlen=100)
        self.step_times = deque(maxlen=1000)
        
        # Timers
        self.last_time = time.time()
        self.last_step = 0
        
        # GPU handle
        self.gpu_handle = None
        if HAS_NVML:
            try:
                self.gpu_handle = pynvml.nvmlDeviceGetHandleByIndex(0)
            except:
                pass
    
    def _on_training_start(self):
        if self.verbose > 0:
            print("\nüìä Performance Monitor activ√©")
            print(f"   Log freq : {self.log_freq:,} steps")
            print(f"   GPU      : {'D√©tect√©' if self.gpu_handle else 'Non disponible'}")
            print(f"   CPU      : {'D√©tect√©' if HAS_PSUTIL else 'Non disponible'}\n")
        
        self.last_time = time.time()
        self.last_step = self.num_timesteps
    
    def _on_step(self) -> bool:
        """
        Calcule FPS et log p√©riodiquement
        """
        current_time = time.time()
        
        # Calculer FPS instantan√©
        steps_done = self.num_timesteps - self.last_step
        time_elapsed = current_time - self.last_time
        
        if time_elapsed > 0:
            fps = steps_done / time_elapsed
            self.fps_buffer.append(fps)
            self.step_times.append(time_elapsed / steps_done if steps_done > 0 else 0)
        
        # Log p√©riodique
        if self.num_timesteps - self.last_log_step >= self.log_freq:
            self._log_performance()
            self.last_log_step = self.num_timesteps
        
        # Update timers
        self.last_time = current_time
        self.last_step = self.num_timesteps
        
        return True
    
    def _log_performance(self):
        """
        Log m√©triques de performance
        """
        metrics = {}
        
        # FPS
        if len(self.fps_buffer) > 0:
            avg_fps = np.mean(list(self.fps_buffer))
            metrics['perf/fps'] = avg_fps
            
            # D√©tection bottleneck FPS
            if avg_fps < 10000:
                status = "‚ùå TR√àS LENT"
            elif avg_fps < 20000:
                status = "‚ö†Ô∏è  LENT"
            elif avg_fps < 30000:
                status = "üü° OK"
            else:
                status = "‚úÖ RAPIDE"
            
            if self.verbose > 0:
                print(f"\n‚è±Ô∏è  Performance (step {self.num_timesteps:,})")
                print(f"   FPS : {avg_fps:,.0f} {status}")
        
        # GPU
        if self.gpu_handle:
            try:
                util = pynvml.nvmlDeviceGetUtilizationRates(self.gpu_handle)
                mem_info = pynvml.nvmlDeviceGetMemoryInfo(self.gpu_handle)
                temp = pynvml.nvmlDeviceGetTemperature(self.gpu_handle, pynvml.NVML_TEMPERATURE_GPU)
                
                gpu_util = util.gpu
                mem_used_gb = mem_info.used / 1024**3
                mem_total_gb = mem_info.total / 1024**3
                
                metrics['perf/gpu_util'] = gpu_util
                metrics['perf/gpu_memory_gb'] = mem_used_gb
                metrics['perf/gpu_temp'] = temp
                
                # D√©tection bottleneck GPU
                if gpu_util < 30:
                    gpu_status = "‚ùå SOUS-UTILIS√â (CPU bottleneck?)"
                elif gpu_util < 60:
                    gpu_status = "‚ö†Ô∏è  Peut mieux faire"
                else:
                    gpu_status = "‚úÖ Bien utilis√©"
                
                if self.verbose > 0:
                    print(f"   GPU : {gpu_util}% {gpu_status}")
                    print(f"   VRAM: {mem_used_gb:.1f}/{mem_total_gb:.1f} GB")
                    print(f"   Temp: {temp}¬∞C")
            except:
                pass
        
        # CPU
        if HAS_PSUTIL:
            cpu_percent = psutil.cpu_percent(interval=0.1)
            metrics['perf/cpu_util'] = cpu_percent
            
            if self.verbose > 0:
                if cpu_percent > 90:
                    cpu_status = "‚ùå SATUR√â (bottleneck!)"
                elif cpu_percent > 70:
                    cpu_status = "‚ö†Ô∏è  Charg√©"
                else:
                    cpu_status = "‚úÖ OK"
                
                print(f"   CPU : {cpu_percent:.0f}% {cpu_status}")
        
        # Step time
        if len(self.step_times) > 0:
            avg_step_time = np.mean(list(self.step_times)) * 1000  # ms
            metrics['perf/step_time_ms'] = avg_step_time
            
            if self.verbose > 0:
                print(f"   Step: {avg_step_time:.2f}ms")
        
        # Logger dans W&B
        if wandb.run is not None:
            wandb.log(metrics, step=self.num_timesteps)
        
        # Diagnostics
        if self.verbose > 0:
            self._print_diagnostics(metrics)
    
    def _print_diagnostics(self, metrics):
        """
        Affiche diagnostics si probl√®mes d√©tect√©s
        """
        fps = metrics.get('perf/fps', 0)
        gpu_util = metrics.get('perf/gpu_util', 100)
        cpu_util = metrics.get('perf/cpu_util', 0)
        
        # Bottleneck CPU
        if cpu_util > 90 and gpu_util < 50:
            print("\n‚ö†Ô∏è  BOTTLENECK CPU D√âTECT√â")
            print("   Solutions:")
            print("   1. R√©duire n_envs (16‚Üí8‚Üí4)")
            print("   2. Utiliser DummyVecEnv au lieu de SubprocVecEnv")
            print("   3. Augmenter batch_size pour compenser\n")
        
        # GPU sous-utilis√©
        elif gpu_util < 30 and fps < 20000:
            print("\n‚ö†Ô∏è  GPU SOUS-UTILIS√â")
            print("   Causes possibles:")
            print("   1. Batch size trop petit")
            print("   2. CPU bottleneck (v√©rifier ci-dessus)")
            print("   3. I/O disk lent (peu probable avec numpy)\n")
        
        # Tout va bien
        elif fps > 25000 and gpu_util > 60:
            print("\n‚úÖ PERFORMANCE OPTIMALE")
            print(f"   FPS: {fps:,.0f}")
            print(f"   GPU: {gpu_util}%\n")
    
    def _on_training_end(self):
        if self.verbose > 0:
            print("\n‚úÖ Performance Monitor termin√©")
            
            if len(self.fps_buffer) > 0:
                avg_fps = np.mean(list(self.fps_buffer))
                print(f"   FPS moyen : {avg_fps:,.0f}")
        
        # Cleanup GPU
        if HAS_NVML:
            try:
                pynvml.nvmlShutdown()
            except:
                pass

if __name__ == '__main__':
    print("\n" + "="*80)
    print("üìä PERFORMANCE MONITOR CALLBACK")
    print("="*80 + "\n")
    
    print("üìù Usage dans train_curriculum.py :\n")
    print("""from core.performance_monitor import PerformanceMonitor

# Cr√©er callback
perf_monitor = PerformanceMonitor(
    log_freq=5000,  # Log toutes les 5k steps
    verbose=1
)

# Combiner avec autres callbacks
callback = CallbackList([
    checkpoint_callback,
    wandb_callback,
    trading_callback,
    perf_monitor  # ‚úÖ Ajout√©
])
""")
    
    print("\nüìä M√©triques logg√©es :")
    print("   perf/fps")
    print("   perf/gpu_util")
    print("   perf/gpu_memory_gb")
    print("   perf/gpu_temp")
    print("   perf/cpu_util")
    print("   perf/step_time_ms")
    print("\n")
