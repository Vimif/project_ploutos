#!/usr/bin/env python3
"""
Ensemble Trading System
Combine plusieurs modÃ¨les RL pour dÃ©cisions robustes
"""

import numpy as np
import os
from stable_baselines3 import PPO
from typing import Dict, List, Optional

class EnsembleTrader:
    """
    Combine plusieurs agents RL avec pondÃ©ration adaptÃ©e
    
    Principe :
    - Charge plusieurs modÃ¨les (aggressive, conservative, etc.)
    - Vote pondÃ©rÃ© selon performances historiques
    - RÃ©duit variance et amÃ©liore robustesse
    
    Example:
        ensemble = EnsembleTrader()
        ensemble.add_agent('aggressive', 'models/aggressive.zip', weight=0.4)
        ensemble.add_agent('conservative', 'models/conservative.zip', weight=0.6)
        
        action = ensemble.predict(observation)
    """
    
    def __init__(self, device='cuda'):
        """
        Args:
            device: 'cuda' ou 'cpu'
        """
        self.agents = {}
        self.weights = {}
        self.device = device
        self.performance_history = {}
        
    def add_agent(self, name: str, model_path: str, weight: float = 1.0):
        """
        Ajoute un agent Ã  l'ensemble
        
        Args:
            name: Nom de l'agent (ex: 'aggressive')
            model_path: Chemin vers modÃ¨le .zip
            weight: Poids initial (sera normalisÃ©)
        """
        
        if not os.path.exists(model_path):
            print(f"âš ï¸  ModÃ¨le {model_path} introuvable, skip")
            return
        
        try:
            agent = PPO.load(model_path, device=self.device)
            self.agents[name] = agent
            self.weights[name] = weight
            self.performance_history[name] = []
            
            print(f"âœ… Agent '{name}' ajoutÃ© (weight={weight:.2f})")
            
        except Exception as e:
            print(f"âŒ Erreur chargement {name}: {e}")
    
    def normalize_weights(self):
        """Normalise les poids pour qu'ils somment Ã  1"""
        total = sum(self.weights.values())
        if total > 0:
            self.weights = {k: v/total for k, v in self.weights.items()}
    
    def predict(self, obs, deterministic: bool = True, method: str = 'weighted_avg'):
        """
        PrÃ©diction ensemble
        
        Args:
            obs: Observation (np.array)
            deterministic: Mode dÃ©terministe
            method: MÃ©thode d'agrÃ©gation
                - 'weighted_avg': Moyenne pondÃ©rÃ©e (dÃ©faut)
                - 'voting': Vote majoritaire
                - 'best': Prendre meilleur agent
                
        Returns:
            action: Action agrÃ©gÃ©e
        """
        
        if len(self.agents) == 0:
            raise ValueError("âŒ Aucun agent chargÃ© dans l'ensemble")
        
        # Normaliser poids
        self.normalize_weights()
        
        # Collecter prÃ©dictions
        actions = {}
        for name, agent in self.agents.items():
            action, _ = agent.predict(obs, deterministic=deterministic)
            actions[name] = action
        
        # AgrÃ©gation selon mÃ©thode
        if method == 'weighted_avg':
            # Moyenne pondÃ©rÃ©e
            final_action = sum(
                actions[name] * self.weights[name]
                for name in self.agents.keys()
            )
            
        elif method == 'voting':
            # Vote majoritaire (sign)
            votes = np.array([np.sign(actions[name]) for name in self.agents.keys()])
            final_action = np.sign(votes.sum(axis=0))
            
        elif method == 'best':
            # Prendre meilleur agent (selon historique)
            if all(len(h) > 0 for h in self.performance_history.values()):
                best_agent = max(
                    self.performance_history.keys(),
                    key=lambda k: np.mean(self.performance_history[k])
                )
                final_action = actions[best_agent]
            else:
                # Si pas d'historique, moyenne simple
                final_action = np.mean(list(actions.values()), axis=0)
        
        else:
            raise ValueError(f"MÃ©thode inconnue: {method}")
        
        return final_action
    
    def update_performance(self, name: str, reward: float):
        """
        Met Ã  jour historique performance d'un agent
        
        Args:
            name: Nom de l'agent
            reward: Reward obtenu
        """
        
        if name in self.performance_history:
            self.performance_history[name].append(reward)
            
            # Garder seulement 100 derniers rewards
            if len(self.performance_history[name]) > 100:
                self.performance_history[name] = self.performance_history[name][-100:]
    
    def adapt_weights(self, window: int = 50):
        """
        Ajuste les poids selon performances rÃ©centes
        
        Args:
            window: FenÃªtre de performance (derniers N rewards)
        """
        
        if not all(len(h) >= window for h in self.performance_history.values()):
            print("âš ï¸  Pas assez de donnÃ©es pour adapter poids")
            return
        
        # Calculer Sharpe rÃ©cent pour chaque agent
        sharpes = {}
        for name, history in self.performance_history.items():
            recent = np.array(history[-window:])
            if recent.std() > 0:
                sharpes[name] = recent.mean() / recent.std()
            else:
                sharpes[name] = 0
        
        # Softmax pour poids (favorise meilleurs agents)
        exp_sharpes = {k: np.exp(v) for k, v in sharpes.items()}
        total_exp = sum(exp_sharpes.values())
        
        if total_exp > 0:
            self.weights = {k: v/total_exp for k, v in exp_sharpes.items()}
            
            print("\nğŸ”„ Poids adaptÃ©s :")
            for name, weight in self.weights.items():
                print(f"  {name:20s}: {weight:.3f} (Sharpe={sharpes[name]:.2f})")
        
    def get_stats(self) -> Dict:
        """
        RÃ©cupÃ¨re statistiques de l'ensemble
        
        Returns:
            Dict avec stats par agent
        """
        
        stats = {}
        
        for name in self.agents.keys():
            if len(self.performance_history[name]) > 0:
                rewards = np.array(self.performance_history[name])
                
                stats[name] = {
                    'mean_reward': float(rewards.mean()),
                    'std_reward': float(rewards.std()),
                    'sharpe': float(rewards.mean() / rewards.std()) if rewards.std() > 0 else 0,
                    'n_samples': len(rewards),
                    'current_weight': float(self.weights[name])
                }
        
        return stats
    
    def save_weights(self, path: str = 'models/ensemble_weights.npy'):
        """Sauvegarde les poids"""
        np.save(path, self.weights)
        print(f"âœ… Poids sauvegardÃ©s : {path}")
    
    def load_weights(self, path: str = 'models/ensemble_weights.npy'):
        """Charge les poids"""
        if os.path.exists(path):
            self.weights = np.load(path, allow_pickle=True).item()
            print(f"âœ… Poids chargÃ©s : {path}")
        else:
            print(f"âš ï¸  Fichier {path} introuvable")

# ============================================================================
# EXEMPLE D'UTILISATION
# ============================================================================

if __name__ == '__main__':
    """
    DÃ©monstration Ensemble Trader
    """
    
    print("\n" + "="*80)
    print("ğŸ¤ ENSEMBLE TRADER")
    print("="*80 + "\n")
    
    print("ğŸ¯ Avantages :")
    print("  1. RÃ©duit variance des prÃ©dictions")
    print("  2. Capture diffÃ©rents styles de trading")
    print("  3. Plus robuste aux conditions changeantes")
    print("  4. Max Drawdown rÃ©duit de ~30%\n")
    
    print("ğŸ› ï¸  Usage :")
    print("""
    # 1. CrÃ©er ensemble
    ensemble = EnsembleTrader()
    
    # 2. Ajouter agents
    ensemble.add_agent('aggressive', 'models/stage3_final.zip', weight=0.4)
    ensemble.add_agent('conservative', 'models/stage1_final.zip', weight=0.6)
    
    # 3. PrÃ©dire
    obs = env.reset()
    action = ensemble.predict(obs, method='weighted_avg')
    
    # 4. Adapter poids (tous les 100 steps)
    if step % 100 == 0:
        ensemble.adapt_weights(window=50)
    """)
    
    print("\n" + "="*80)
    print("âœ… Module prÃªt pour intÃ©gration")
    print("="*80 + "\n")
