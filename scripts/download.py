#!/usr/bin/env python3
"""
Download Historical Data Script (Fixed)
=======================================

T√©l√©charge les donn√©es historiques via yfinance avec une p√©riode ajust√©e
pour respecter la limite stricte de 730 jours de Yahoo Finance pour les donn√©es horaires.

Usage:
    python scripts/download_data.py
"""

import os
import yfinance as yf
import pandas as pd
from datetime import datetime, timedelta

# Configuration du projet
TICKERS = [
    # GROWTH
    "NVDA", "MSFT", "AAPL", "GOOGL", "AMZN",
    # DEFENSIVE
    "SPY", "QQQ", "VOO", "VTI",
    # ENERGY
    "XOM", "CVX", "COP", "XLE",
    # FINANCE
    "JPM", "BAC", "WFC", "GS"
]

# FIX: Yahoo Finance est tr√®s strict sur la limite de 730 jours pour les donn√©es 1h.
# On prend 720 jours pour √™tre s√ªr (marge de s√©curit√©).
DAYS_BACK = 720
START_DATE = (datetime.now() - timedelta(days=DAYS_BACK)).strftime('%Y-%m-%d')
END_DATE = datetime.now().strftime('%Y-%m-%d')
OUTPUT_FILE = "data/historical_daily.csv"
INTERVAL = "1h"

def download_and_process():
    print(f"üöÄ D√©marrage du t√©l√©chargement pour {len(TICKERS)} tickers...")
    print(f"üìÖ P√©riode: {START_DATE} √† {END_DATE} ({DAYS_BACK} jours)")
    print(f"‚è±Ô∏è  Intervalle: {INTERVAL}")

    os.makedirs("data", exist_ok=True)

    all_data = []

    for ticker in TICKERS:
        print(f"  ‚¨áÔ∏è  Downloading {ticker}...", end=" ", flush=True)
        try:
            # FIX: auto_adjust=True pour √©viter le warning
            df = yf.download(
                ticker, 
                start=START_DATE, 
                end=END_DATE, 
                interval=INTERVAL, 
                progress=False,
                auto_adjust=True
            )
            
            if len(df) == 0:
                print(f"‚ùå Empty data!")
                continue

            # Aplatir le MultiIndex si n√©cessaire
            if isinstance(df.columns, pd.MultiIndex):
                # Si colonnes sont ('Close', 'NVDA'), on garde juste 'Close'
                # Yahoo a chang√© son format r√©cemment
                try:
                    df = df.xs(ticker, axis=1, level=1, drop_level=True)
                except:
                    # Fallback si structure diff√©rente
                    df.columns = df.columns.get_level_values(0)
            
            # Reset index pour avoir la date en colonne
            df = df.reset_index()
            
            # Renommer la colonne date
            # Yahoo retourne souvent 'Datetime' pour les donn√©es intraday
            date_col = None
            for col in df.columns:
                if 'Date' in str(col) or 'Time' in str(col):
                    date_col = col
                    break
            
            if date_col:
                df = df.rename(columns={date_col: 'Date'})
            else:
                print("‚ùå Date column not found")
                continue
            
            # Ajouter la colonne Ticker
            df['Ticker'] = ticker
            
            # S√©lectionner les colonnes n√©cessaires
            required_cols = ['Date', 'Ticker', 'Open', 'High', 'Low', 'Close', 'Volume']
            available_cols = [c for c in required_cols if c in df.columns]
            
            if len(available_cols) < 5: # Au moins OHLCV
                print(f"‚ùå Missing columns. Got: {df.columns}")
                continue
                
            df = df[available_cols]
            
            all_data.append(df)
            print(f"‚úÖ {len(df)} rows")
            
        except Exception as e:
            print(f"‚ùå Error: {e}")

    if not all_data:
        print("\n‚ùå √âCHEC TOTAL: Aucune donn√©e r√©cup√©r√©e.")
        print("üí° Solution de secours: Utilisation de donn√©es journali√®res ('1d') au lieu de horaires ('1h')")
        print("   Cela permet d'avoir plus d'historique et √©vite la limite de 730 jours.")
        
        retry = input("Voulez-vous essayer avec des donn√©es journali√®res ? (y/n) ")
        if retry.lower() == 'y':
            download_daily_fallback()
        return

    # Concat√©nation
    print("\nüîÑ Fusion des donn√©es...")
    final_df = pd.concat(all_data, ignore_index=True)
    
    # Nettoyage
    final_df = final_df.sort_values(['Ticker', 'Date'])
    final_df = final_df.dropna()

    # Sauvegarde
    print(f"üíæ Sauvegarde vers {OUTPUT_FILE}...")
    final_df.to_csv(OUTPUT_FILE, index=False)
    
    print("\n‚úÖ T√âL√âCHARGEMENT TERMIN√â!")
    print(f"üìä Total lignes: {len(final_df)}")
    print(f"üìà Tickers: {final_df['Ticker'].nunique()}")
    print("\nüëâ Vous pouvez maintenant lancer l'entra√Ænement :")
    print(f"   python scripts/train_v6_final.py --data {OUTPUT_FILE}")

def download_daily_fallback():
    """Fallback to daily data if hourly fails"""
    print("\nüöÄ T√©l√©chargement donn√©es JOURNALI√àRES (Fallback)...")
    # 5 ans d'historique pour daily
    start = (datetime.now() - timedelta(days=365*5)).strftime('%Y-%m-%d')
    end = datetime.now().strftime('%Y-%m-%d')
    
    all_data = []
    for ticker in TICKERS:
        print(f"  ‚¨áÔ∏è  Downloading {ticker} (1d)...", end=" ")
        try:
            df = yf.download(ticker, start=start, end=end, interval="1d", progress=False, auto_adjust=True)
            if isinstance(df.columns, pd.MultiIndex):
                try:
                    df = df.xs(ticker, axis=1, level=1, drop_level=True)
                except:
                    df.columns = df.columns.get_level_values(0)
            
            df = df.reset_index()
            # Rename Date
            col_map = {c: 'Date' for c in df.columns if 'Date' in str(c)}
            df = df.rename(columns=col_map)
            df['Ticker'] = ticker
            all_data.append(df)
            print(f"‚úÖ {len(df)} rows")
        except Exception as e:
            print(f"‚ùå {e}")
            
    if all_data:
        final_df = pd.concat(all_data, ignore_index=True)
        final_df.to_csv(OUTPUT_FILE, index=False)
        print(f"\n‚úÖ Sauvegard√© dans {OUTPUT_FILE} (Donn√©es journali√®res)")
        print("‚ö†Ô∏è  Note: L'entra√Ænement sera moins pr√©cis pour l'intraday mais fonctionnera.")

if __name__ == "__main__":
    download_and_process()
