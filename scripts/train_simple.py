#!/usr/bin/env python3
"""
Script d'entraÃ®nement simplifiÃ© - Assets fixes
"""
import os
import sys
import pandas as pd
from pathlib import Path
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv

# Ajouter le parent au path
sys.path.insert(0, str(Path(__file__).parent.parent))

from core.universal_environment import UniversalTradingEnv

print("ğŸš€ ENTRAÃNEMENT SIMPLIFIÃ‰\n")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. CHARGER DONNÃ‰ES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("ğŸ“¥ Chargement donnÃ©es...\n")

TICKERS = ['NVDA', 'MSFT', 'AAPL']
data = {}

for ticker in TICKERS:
    file_path = f'data_cache/{ticker}.csv'
    if os.path.exists(file_path):
        df = pd.read_csv(file_path, index_col=0, parse_dates=True)
        data[ticker] = df
        print(f"  âœ… {ticker}: {len(df)} lignes")
    else:
        print(f"  âŒ {ticker}: fichier manquant")

if len(data) == 0:
    print("\nâŒ Aucune donnÃ©e chargÃ©e")
    sys.exit(1)

print(f"\nâœ… {len(data)} datasets chargÃ©s\n")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. CRÃ‰ER ENVIRONNEMENT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("ğŸ—ï¸  CrÃ©ation environnement...\n")

def make_env():
    return UniversalTradingEnv(
        data=data,
        initial_balance=100000,
        commission=0.001,
        max_steps=200
    )

env = DummyVecEnv([make_env])
print("  âœ… Environnement crÃ©Ã©\n")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. CRÃ‰ER MODÃˆLE PPO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("ğŸ¤– CrÃ©ation modÃ¨le PPO...\n")

model = PPO(
    "MlpPolicy",
    env,
    learning_rate=0.0001,
    n_steps=2048,
    batch_size=256,
    n_epochs=10,
    gamma=0.99,
    verbose=1,
    device='cuda',
    tensorboard_log='logs/tensorboard',
    policy_kwargs=dict(
        net_arch=dict(pi=[256, 256], vf=[256, 256])
    )
)

print("  âœ… ModÃ¨le crÃ©Ã©\n")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. ENTRAÃNEMENT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("ğŸ‹ï¸  DÃ‰BUT ENTRAÃNEMENT\n")
print("  Timesteps: 50,000")
print("  Device   : cuda")
print("  Assets   : NVDA, MSFT, AAPL")
print()

try:
    model.learn(
        total_timesteps=50000,
        progress_bar=True
    )
    print("\nâœ… ENTRAÃNEMENT TERMINÃ‰\n")
    
except KeyboardInterrupt:
    print("\nâš ï¸  Interrompu par utilisateur\n")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5. SAUVEGARDER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

os.makedirs('models/test', exist_ok=True)
model.save('models/test/simple_model.zip')
print("ğŸ’¾ ModÃ¨le sauvegardÃ©: models/test/simple_model.zip\n")

env.close()
print("âœ… TERMINÃ‰")
