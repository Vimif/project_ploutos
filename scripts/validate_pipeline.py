#!/usr/bin/env python3
# scripts/validate_pipeline.py
"""Pipeline de validation automatique: train â†’ val â†’ backtest â†’ certification.

ExÃ©cute tout le workflow de validation en une seule commande:
    1. TÃ©lÃ©charge les donnÃ©es
    2. Split temporel train/val/test
    3. EntraÃ®ne un modÃ¨le rapide (ou utilise un modÃ¨le existant)
    4. Ã‰value sur les donnÃ©es de validation
    5. Backtest sur les donnÃ©es de test (OOS)
    6. Calcule les mÃ©triques de certification
    7. GÃ©nÃ¨re un rapport

Usage:
    # Validation complÃ¨te (entraÃ®nement + backtest)
    python scripts/validate_pipeline.py --tickers AAPL MSFT NVDA --timesteps 100000

    # Validation d'un modÃ¨le existant
    python scripts/validate_pipeline.py --model models/v7_sp500/best.zip --tickers AAPL MSFT NVDA

    # Validation rapide (smoke test)
    python scripts/validate_pipeline.py --quick
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

import os
import json
import warnings
import argparse
import numpy as np
from datetime import datetime

warnings.filterwarnings('ignore', message='.*Gym has been unmaintained.*')

from core.data_fetcher import download_data
from core.data_pipeline import DataSplitter
from core.universal_environment_v6_better_timing import UniversalTradingEnvV6BetterTiming


def run_validation(
    tickers: list[str],
    model_path: str | None = None,
    total_timesteps: int = 100_000,
    period: str = '2y',
    interval: str = '1h',
    train_ratio: float = 0.6,
    val_ratio: float = 0.2,
    test_ratio: float = 0.2,
    seed: int = 42,
    output_dir: str = 'reports/validation',
) -> dict:
    """Pipeline de validation complet.

    Args:
        tickers: Liste de tickers Ã  utiliser.
        model_path: Chemin vers un modÃ¨le existant (si None, entraÃ®ne un nouveau).
        total_timesteps: Nombre de timesteps pour l'entraÃ®nement rapide.
        period: PÃ©riode de donnÃ©es.
        interval: Intervalle de donnÃ©es.
        train_ratio: Ratio train.
        val_ratio: Ratio validation.
        test_ratio: Ratio test (OOS).
        seed: Seed pour reproductibilitÃ©.
        output_dir: Dossier de sortie pour le rapport.

    Returns:
        Dict avec les rÃ©sultats de validation.
    """
    results = {
        'timestamp': datetime.now().isoformat(),
        'tickers': tickers,
        'seed': seed,
        'stages': {},
    }

    print("=" * 70)
    print("ğŸš€ PIPELINE DE VALIDATION")
    print("=" * 70)

    # ================================================================
    # Stage 1: Download data
    # ================================================================
    print(f"\nğŸ“¥ Stage 1/6: TÃ©lÃ©chargement des donnÃ©es...")
    try:
        data = download_data(tickers, period=period, interval=interval)
        if not data or len(data) == 0:
            raise ValueError("Aucune donnÃ©e rÃ©cupÃ©rÃ©e")

        print(f"  âœ… {len(data)} tickers chargÃ©s")
        for t, df in data.items():
            print(f"     {t}: {len(df)} bars")

        results['stages']['download'] = {
            'status': 'OK',
            'n_tickers': len(data),
            'bars_per_ticker': {t: len(df) for t, df in data.items()},
        }
    except Exception as e:
        print(f"  âŒ Erreur: {e}")
        results['stages']['download'] = {'status': 'FAIL', 'error': str(e)}
        return results

    # ================================================================
    # Stage 2: Split temporel
    # ================================================================
    print(f"\nğŸ“Š Stage 2/6: Split temporel ({train_ratio}/{val_ratio}/{test_ratio})...")
    try:
        splits = DataSplitter.split(data, train_ratio, val_ratio, test_ratio)
        DataSplitter.validate_no_overlap(splits)

        print(f"  âœ… Train: {splits.info['train']['n_bars']} bars")
        print(f"  âœ… Val:   {splits.info['val']['n_bars']} bars")
        print(f"  âœ… Test:  {splits.info['test']['n_bars']} bars")
        print(f"  âœ… Pas de chevauchement temporel")

        results['stages']['split'] = {
            'status': 'OK',
            'info': splits.info,
        }
    except Exception as e:
        print(f"  âŒ Erreur: {e}")
        results['stages']['split'] = {'status': 'FAIL', 'error': str(e)}
        return results

    # ================================================================
    # Stage 3: Training (ou chargement modÃ¨le)
    # ================================================================
    if model_path and os.path.exists(model_path):
        print(f"\nğŸ“¦ Stage 3/6: Chargement du modÃ¨le existant...")
        print(f"  â†’ {model_path}")

        try:
            from stable_baselines3 import PPO
            model = PPO.load(model_path)
            print(f"  âœ… ModÃ¨le chargÃ©")
            results['stages']['training'] = {
                'status': 'OK (loaded)',
                'model_path': model_path,
            }
        except Exception as e:
            print(f"  âŒ Erreur: {e}")
            results['stages']['training'] = {'status': 'FAIL', 'error': str(e)}
            return results
    else:
        print(f"\nğŸ‹ï¸ Stage 3/6: EntraÃ®nement rapide ({total_timesteps:,} steps)...")
        try:
            import torch
            from stable_baselines3 import PPO
            from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize
            from stable_baselines3.common.monitor import Monitor

            train_env = DummyVecEnv([
                lambda: Monitor(UniversalTradingEnvV6BetterTiming(
                    splits.train, mode='train', seed=seed,
                ))
            ])
            train_env = VecNormalize(
                train_env, norm_obs=True, norm_reward=True,
                clip_obs=10.0, clip_reward=10.0,
            )

            device = 'cuda' if torch.cuda.is_available() else 'cpu'
            model = PPO(
                'MlpPolicy', train_env,
                learning_rate=3e-4, n_steps=512, batch_size=64,
                n_epochs=5, verbose=0, device=device, seed=seed,
            )

            model.learn(total_timesteps=total_timesteps, progress_bar=True)
            print(f"  âœ… EntraÃ®nement terminÃ© ({device})")

            results['stages']['training'] = {
                'status': 'OK',
                'total_timesteps': total_timesteps,
                'device': device,
            }

        except Exception as e:
            print(f"  âŒ Erreur: {e}")
            import traceback
            traceback.print_exc()
            results['stages']['training'] = {'status': 'FAIL', 'error': str(e)}
            return results

    # ================================================================
    # Stage 4: Evaluation (val data)
    # ================================================================
    print(f"\nğŸ“ˆ Stage 4/6: Ã‰valuation sur donnÃ©es de validation...")
    try:
        val_env = UniversalTradingEnvV6BetterTiming(
            splits.val, mode='eval', seed=seed,
        )
        val_results = _run_episodes(model, val_env, n_episodes=3, label='Val')
        results['stages']['validation'] = {
            'status': 'OK',
            **val_results,
        }
    except Exception as e:
        print(f"  âŒ Erreur: {e}")
        results['stages']['validation'] = {'status': 'FAIL', 'error': str(e)}

    # ================================================================
    # Stage 5: Backtest OOS (test data)
    # ================================================================
    print(f"\nğŸ¯ Stage 5/6: Backtest Out-of-Sample (donnÃ©es test)...")
    try:
        test_env = UniversalTradingEnvV6BetterTiming(
            splits.test, mode='backtest', seed=seed,
        )
        oos_results = _run_episodes(model, test_env, n_episodes=1, label='OOS')
        results['stages']['oos_backtest'] = {
            'status': 'OK',
            **oos_results,
        }
    except Exception as e:
        print(f"  âŒ Erreur: {e}")
        results['stages']['oos_backtest'] = {'status': 'FAIL', 'error': str(e)}

    # ================================================================
    # Stage 6: Certification
    # ================================================================
    print(f"\nğŸ† Stage 6/6: Certification...")
    cert = _certify(results)
    results['stages']['certification'] = cert

    # ================================================================
    # Sauvegarde rapport
    # ================================================================
    os.makedirs(output_dir, exist_ok=True)
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    report_path = os.path.join(output_dir, f'validation_{timestamp}.json')
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False, default=str)
    print(f"\nğŸ“„ Rapport sauvegardÃ©: {report_path}")

    _print_summary(results)
    return results


def _run_episodes(model, env, n_episodes: int, label: str) -> dict:
    """Execute n Ã©pisodes et retourne les mÃ©triques."""
    all_returns = []
    all_trades = []
    all_win_rates = []

    for ep in range(n_episodes):
        obs, info = env.reset()
        done = False
        ep_reward = 0.0

        while not done:
            action, _ = model.predict(obs, deterministic=True)
            obs, reward, done, trunc, info = env.step(action)
            ep_reward += reward

        total_return = info.get('total_return', 0.0)
        trades = info.get('total_trades', 0)
        wins = info.get('winning_trades', 0)
        win_rate = wins / max(trades, 1)

        all_returns.append(total_return)
        all_trades.append(trades)
        all_win_rates.append(win_rate)

        print(
            f"  [{label}] Ep {ep + 1}/{n_episodes}: "
            f"Return={total_return * 100:.2f}% | "
            f"Trades={trades} | "
            f"WR={win_rate:.1%}"
        )

    return {
        'mean_return': float(np.mean(all_returns)),
        'std_return': float(np.std(all_returns)),
        'mean_trades': float(np.mean(all_trades)),
        'mean_win_rate': float(np.mean(all_win_rates)),
        'n_episodes': n_episodes,
    }


def _certify(results: dict) -> dict:
    """Ã‰value la qualitÃ© du modÃ¨le et dÃ©termine s'il est certifiÃ©."""
    cert = {'checks': {}}

    # Check 1: OOS return > 0
    oos = results['stages'].get('oos_backtest', {})
    oos_return = oos.get('mean_return', -1)
    cert['checks']['oos_positive_return'] = oos_return > 0

    # Check 2: OOS win rate > 50%
    oos_wr = oos.get('mean_win_rate', 0)
    cert['checks']['oos_win_rate_gt_50'] = oos_wr > 0.5

    # Check 3: OOS trades > 0
    oos_trades = oos.get('mean_trades', 0)
    cert['checks']['oos_has_trades'] = oos_trades > 0

    # Check 4: Val return direction matches OOS
    val = results['stages'].get('validation', {})
    val_return = val.get('mean_return', 0)
    cert['checks']['val_oos_direction_match'] = (
        (val_return > 0 and oos_return > 0)
        or (val_return <= 0 and oos_return <= 0)
    )

    # Verdict
    n_passed = sum(1 for v in cert['checks'].values() if v)
    n_total = len(cert['checks'])
    cert['passed'] = n_passed
    cert['total'] = n_total
    cert['certified'] = n_passed == n_total
    cert['status'] = 'CERTIFIED âœ…' if cert['certified'] else f'FAILED ({n_passed}/{n_total})'

    return cert


def _print_summary(results: dict):
    """Affiche un rÃ©sumÃ© lisible."""
    print("\n" + "=" * 70)
    print("ğŸ“‹ RÃ‰SUMÃ‰ DE VALIDATION")
    print("=" * 70)

    for stage_name, stage_data in results['stages'].items():
        status = stage_data.get('status', '?')
        icon = 'âœ…' if 'OK' in str(status) or 'CERTIFIED' in str(status) else 'âŒ'
        print(f"  {icon} {stage_name}: {status}")

    cert = results['stages'].get('certification', {})
    if cert:
        print(f"\n  ğŸ† Certification: {cert.get('status', '?')}")
        for check, passed in cert.get('checks', {}).items():
            icon = 'âœ…' if passed else 'âŒ'
            print(f"     {icon} {check}")

    print("=" * 70)


# ======================================================================
# CLI
# ======================================================================
if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description='Pipeline de validation: train â†’ val â†’ backtest â†’ certification'
    )
    parser.add_argument(
        '--tickers', nargs='+', default=['AAPL', 'MSFT', 'NVDA'],
        help='Tickers Ã  utiliser (dÃ©faut: AAPL MSFT NVDA)',
    )
    parser.add_argument(
        '--model', type=str, default=None,
        help='Chemin vers un modÃ¨le existant (skip training)',
    )
    parser.add_argument(
        '--timesteps', type=int, default=100_000,
        help='Nombre de timesteps pour entraÃ®nement rapide (dÃ©faut: 100K)',
    )
    parser.add_argument(
        '--period', type=str, default='2y',
        help='PÃ©riode de donnÃ©es (dÃ©faut: 2y)',
    )
    parser.add_argument(
        '--quick', action='store_true',
        help='Mode rapide (10K steps, 3 tickers)',
    )
    parser.add_argument(
        '--seed', type=int, default=42,
        help='Seed pour reproductibilitÃ© (dÃ©faut: 42)',
    )
    parser.add_argument(
        '--output', type=str, default='reports/validation',
        help='Dossier de sortie (dÃ©faut: reports/validation)',
    )

    args = parser.parse_args()

    if args.quick:
        args.tickers = ['AAPL', 'MSFT', 'NVDA']
        args.timesteps = 10_000

    run_validation(
        tickers=args.tickers,
        model_path=args.model,
        total_timesteps=args.timesteps,
        period=args.period,
        seed=args.seed,
        output_dir=args.output,
    )
