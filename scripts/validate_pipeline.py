#!/usr/bin/env python3
# scripts/validate_pipeline.py
"""Pipeline de validation automatique: train â†’ val â†’ backtest â†’ certification.

ExÃ©cute tout le workflow de validation en une seule commande:
    1. TÃ©lÃ©charge les donnÃ©es
    2. Split temporel train/val/test
    3. EntraÃ®ne un modÃ¨le rapide (ou utilise un modÃ¨le existant)
    4. Ã‰value sur les donnÃ©es de validation
    5. Backtest sur les donnÃ©es de test (OOS)
    6. Calcule les mÃ©triques de certification
    7. GÃ©nÃ¨re un rapport

Usage:
    # Validation complÃ¨te (entraÃ®nement + backtest)
    python scripts/validate_pipeline.py --tickers AAPL MSFT NVDA --timesteps 100000

    # Validation d'un modÃ¨le existant
    python scripts/validate_pipeline.py --model models/v7_sp500/best.zip --tickers AAPL MSFT NVDA

    # Validation rapide (smoke test)
    python scripts/validate_pipeline.py --quick
"""

import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

import os
import json
import warnings
import argparse
import numpy as np
from datetime import datetime

warnings.filterwarnings("ignore", message=".*Gym has been unmaintained.*")

from core.data_fetcher import download_data
from core.data_pipeline import DataSplitter
from core.environment import TradingEnv
from core.features import FeatureEngineer  # V9 Turbo


def run_validation(
    tickers: list[str],
    model_path: str | None = None,
    total_timesteps: int = 100_000,
    period: str = "2y",
    interval: str = "1h",
    train_ratio: float = 0.6,
    val_ratio: float = 0.2,
    test_ratio: float = 0.2,
    seed: int = 42,
    output_dir: str = "reports/validation",
) -> dict:
    """Pipeline de validation complet."""
    results = {
        "timestamp": datetime.now().isoformat(),
        "tickers": tickers,
        "seed": seed,
        "stages": {},
    }

    print("=" * 70)
    print("ğŸš€ PIPELINE DE VALIDATION (V9)")
    print("=" * 70)

    # ================================================================
    # Stage 1: Download data & Feature Engineering
    # ================================================================
    print(f"\nğŸ“¥ Stage 1/6: TÃ©lÃ©chargement & Features...")
    try:
        data = download_data(tickers, period=period, interval=interval)
        if not data or len(data) == 0:
            raise ValueError("Aucune donnÃ©e rÃ©cupÃ©rÃ©e")

        # V9: Calculate Features immediately
        fe = FeatureEngineer()
        for t, df in data.items():
            data[t] = fe.calculate_all_features(df)

        print(f"  âœ… {len(data)} tickers chargÃ©s & features calculÃ©es")

        results["stages"]["download"] = {
            "status": "OK",
            "n_tickers": len(data),
            "bars_per_ticker": {t: len(df) for t, df in data.items()},
        }
    except Exception as e:
        print(f"  âŒ Erreur: {e}")
        results["stages"]["download"] = {"status": "FAIL", "error": str(e)}
        return results

    # ================================================================
    # Stage 2: Split temporel
    # ================================================================
    print(f"\nğŸ“Š Stage 2/6: Split temporel ({train_ratio}/{val_ratio}/{test_ratio})...")
    try:
        splits = DataSplitter.split(data, train_ratio, val_ratio, test_ratio)
        DataSplitter.validate_no_overlap(splits)
        # ... logs ...
        results["stages"]["split"] = {"status": "OK", "info": splits.info}
    except Exception as e:
        print(f"  âŒ Erreur: {e}")
        results["stages"]["split"] = {"status": "FAIL", "error": str(e)}
        return results

    # ================================================================
    # Stage 3: Training (ou chargement modÃ¨le)
    # ================================================================
    print(f"\nğŸ§  Stage 3/6: Training (Timesteps={total_timesteps})...")

    from stable_baselines3 import PPO
    from stable_baselines3.common.vec_env import DummyVecEnv
    from stable_baselines3.common.monitor import Monitor

    if model_path:
        print(f"  ğŸ“‚ Chargement modÃ¨le existant: {model_path}")
        try:
            model = PPO.load(model_path)
            # Create dummy env for type hinting mostly, PPO.load restores stricture
            pass
        except Exception as e:
            print(f"  âŒ Erreur chargement: {e}")
            results["stages"]["training"] = {"status": "FAIL", "error": str(e)}
            return results
    else:
        try:
            # Utiliser TradingEnv V9 avec features_precomputed=True
            train_env = DummyVecEnv(
                [
                    lambda: Monitor(
                        TradingEnv(
                            splits.train,
                            mode="train",
                            seed=seed,
                            features_precomputed=True,
                        )
                    )
                ]
            )

            model = PPO(
                "MlpPolicy",
                train_env,
                verbose=1,
                seed=seed,
                learning_rate=0.0003,
                n_steps=2048,
                batch_size=64,
                n_epochs=10,
                gamma=0.99,
                gae_lambda=0.95,
                clip_range=0.2,
                ent_coef=0.01,
                vf_coef=0.5,
                max_grad_norm=0.5,
            )

            model.learn(total_timesteps=total_timesteps, progress_bar=False)
            print("  âœ… Training terminÃ©")

            results["stages"]["training"] = {
                "status": "OK",
                "timesteps": total_timesteps,
            }

        except Exception as e:
            print(f"  âŒ Erreur training: {e}")
            results["stages"]["training"] = {"status": "FAIL", "error": str(e)}
            return results

    # ================================================================
    # Stage 4: Evaluation (val data)
    # ================================================================
    print(f"\nğŸ“ˆ Stage 4/6: Ã‰valuation sur donnÃ©es de validation...")
    try:
        val_env = TradingEnv(splits.val, mode="eval", seed=seed, features_precomputed=True)
        val_results = _run_episodes(model, val_env, n_episodes=3, label="Val")
        results["stages"]["validation"] = {"status": "OK", **val_results}
    except Exception as e:
        print(f"  âŒ Erreur: {e}")
        results["stages"]["validation"] = {"status": "FAIL", "error": str(e)}

    # ================================================================
    # Stage 5: Backtest OOS (test data)
    # ================================================================
    print(f"\nğŸ¯ Stage 5/6: Backtest Out-of-Sample (donnÃ©es test)...")
    try:
        test_env = TradingEnv(splits.test, mode="backtest", seed=seed, features_precomputed=True)
        oos_results = _run_episodes(model, test_env, n_episodes=1, label="OOS")

        results["stages"]["oos_backtest"] = {
            "status": "OK",
            **oos_results,
        }
    except Exception as e:
        print(f"  âŒ Erreur: {e}")
        results["stages"]["oos_backtest"] = {"status": "FAIL", "error": str(e)}

    # ================================================================
    # Stage 6: Certification
    # ================================================================
    print(f"\nğŸ† Stage 6/6: Certification...")
    cert = _certify(results)
    results["stages"]["certification"] = cert

    # ================================================================
    # Sauvegarde rapport
    # ================================================================
    os.makedirs(output_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_path = os.path.join(output_dir, f"validation_{timestamp}.json")
    with open(report_path, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, ensure_ascii=False, default=str)
    print(f"\nğŸ“„ Rapport sauvegardÃ©: {report_path}")

    _print_summary(results)
    return results


def _run_episodes(model, env, n_episodes: int, label: str) -> dict:
    """Execute n Ã©pisodes et retourne les mÃ©triques."""
    all_returns = []
    all_trades = []
    all_win_rates = []

    for ep in range(n_episodes):
        obs, info = env.reset()
        done = False
        ep_reward = 0.0

        while not done:
            action, _ = model.predict(obs, deterministic=True)
            obs, reward, done, trunc, info = env.step(action)
            ep_reward += reward

        total_return = info.get("total_return", 0.0)
        trades = info.get("total_trades", 0)
        wins = info.get("winning_trades", 0)
        win_rate = wins / max(trades, 1)

        all_returns.append(total_return)
        all_trades.append(trades)
        all_win_rates.append(win_rate)

        print(
            f"  [{label}] Ep {ep + 1}/{n_episodes}: "
            f"Return={total_return * 100:.2f}% | "
            f"Trades={trades} | "
            f"WR={win_rate:.1%}"
        )

    return {
        "mean_return": float(np.mean(all_returns)),
        "std_return": float(np.std(all_returns)),
        "mean_trades": float(np.mean(all_trades)),
        "mean_win_rate": float(np.mean(all_win_rates)),
        "n_episodes": n_episodes,
    }


def _certify(results: dict) -> dict:
    """Ã‰value la qualitÃ© du modÃ¨le et dÃ©termine s'il est certifiÃ©."""
    cert = {"checks": {}}

    # Check 1: OOS return > 0
    oos = results["stages"].get("oos_backtest", {})
    oos_return = oos.get("mean_return", -1)
    cert["checks"]["oos_positive_return"] = oos_return > 0

    # Check 2: OOS win rate > 50%
    oos_wr = oos.get("mean_win_rate", 0)
    cert["checks"]["oos_win_rate_gt_50"] = oos_wr > 0.5

    # Check 3: OOS trades > 0
    oos_trades = oos.get("mean_trades", 0)
    cert["checks"]["oos_has_trades"] = oos_trades > 0

    # Check 4: Val return direction matches OOS
    val = results["stages"].get("validation", {})
    val_return = val.get("mean_return", 0)
    cert["checks"]["val_oos_direction_match"] = (val_return > 0 and oos_return > 0) or (
        val_return <= 0 and oos_return <= 0
    )

    # Verdict
    n_passed = sum(1 for v in cert["checks"].values() if v)
    n_total = len(cert["checks"])
    cert["passed"] = n_passed
    cert["total"] = n_total
    cert["certified"] = n_passed == n_total
    cert["status"] = "CERTIFIED âœ…" if cert["certified"] else f"FAILED ({n_passed}/{n_total})"

    return cert


def _print_summary(results: dict):
    """Affiche un rÃ©sumÃ© lisible."""
    print("\n" + "=" * 70)
    print("ğŸ“‹ RÃ‰SUMÃ‰ DE VALIDATION")
    print("=" * 70)

    for stage_name, stage_data in results["stages"].items():
        status = stage_data.get("status", "?")
        icon = "âœ…" if "OK" in str(status) or "CERTIFIED" in str(status) else "âŒ"
        print(f"  {icon} {stage_name}: {status}")

    cert = results["stages"].get("certification", {})
    if cert:
        print(f"\n  ğŸ† Certification: {cert.get('status', '?')}")
        for check, passed in cert.get("checks", {}).items():
            icon = "âœ…" if passed else "âŒ"
            print(f"     {icon} {check}")

    print("=" * 70)


# ======================================================================
# CLI
# ======================================================================
if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Pipeline de validation: train â†’ val â†’ backtest â†’ certification"
    )
    parser.add_argument(
        "--tickers",
        nargs="+",
        default=["AAPL", "MSFT", "NVDA"],
        help="Tickers Ã  utiliser (dÃ©faut: AAPL MSFT NVDA)",
    )
    parser.add_argument(
        "--model",
        type=str,
        default=None,
        help="Chemin vers un modÃ¨le existant (skip training)",
    )
    parser.add_argument(
        "--timesteps",
        type=int,
        default=100_000,
        help="Nombre de timesteps pour entraÃ®nement rapide (dÃ©faut: 100K)",
    )
    parser.add_argument(
        "--period",
        type=str,
        default="2y",
        help="PÃ©riode de donnÃ©es (dÃ©faut: 2y)",
    )
    parser.add_argument(
        "--quick",
        action="store_true",
        help="Mode rapide (10K steps, 3 tickers)",
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=42,
        help="Seed pour reproductibilitÃ© (dÃ©faut: 42)",
    )
    parser.add_argument(
        "--output",
        type=str,
        default="reports/validation",
        help="Dossier de sortie (dÃ©faut: reports/validation)",
    )

    args = parser.parse_args()

    if args.quick:
        args.tickers = ["AAPL", "MSFT", "NVDA"]
        args.timesteps = 10_000

    run_validation(
        tickers=args.tickers,
        model_path=args.model,
        total_timesteps=args.timesteps,
        period=args.period,
        seed=args.seed,
        output_dir=args.output,
    )
