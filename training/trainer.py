import sys
import os
import time
import pandas as pd
import yfinance as yf
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import SubprocVecEnv
from stable_baselines3.common.callbacks import CheckpointCallback
from wandb.integration.sb3 import WandbCallback
import wandb
import warnings

warnings.filterwarnings("ignore", category=UserWarning, module="gym")
warnings.filterwarnings("ignore", category=DeprecationWarning)

# Import du projet
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from core.environment import TradingEnv
from config.settings import TRAINING_CONFIG, WANDB_CONFIG, USE_GPU

# --- CONFIGURATION ---
N_ENVS = 32            # Nombre d'environnements parall√®les (CPU)
BATCH_SIZE = 4096      # Taille du batch pour GPU
N_STEPS = 2048         # Pas par environnement
TIMESTEPS = 5_000_000  # Dur√©e totale

def print_header(ticker, current, total):
    """Affiche un joli header styl√©"""
    print("\n" + "="*70)
    print(f"üöÄ ENTRA√éNEMENT [{current}/{total}] : {ticker}")
    print("="*70)
    print(f"üìÖ Date : {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"üñ•Ô∏è  Machine : {os.uname().nodename}")
    print(f"üîß Coeurs CPU : {N_ENVS} envs parall√®les")
    print(f"üéÆ GPU Mode : {'ACTIV√â (CUDA)' if USE_GPU else 'D√âSACTIV√â (CPU)'}")
    print("="*70 + "\n")

def download_and_cache_data(ticker, data_dir="data_cache"):
    """T√©l√©charge et met en cache les donn√©es (Max 730j pour 1h)"""
    os.makedirs(data_dir, exist_ok=True)
    file_path = f"{data_dir}/{ticker}.csv"
    
    # V√©rifier cache r√©cent (< 24h pour √™tre s√ªr d'avoir les derni√®res donn√©es)
    if os.path.exists(file_path):
        file_age_hours = (pd.Timestamp.now() - pd.Timestamp(os.path.getmtime(file_path), unit='s')).total_seconds() / 3600
        if file_age_hours < 24:
            print(f"üìÇ [CACHE] Chargement depuis le disque : {ticker} ({file_age_hours:.1f}h old)")
            return file_path
    
    print(f"üì• [YAHOO] T√©l√©chargement des donn√©es pour {ticker} (2 ans, 1h)...")
    try:
        # ATTENTION: period="730d" maximum pour interval="1h"
        df = yf.download(ticker, period="730d", interval="1h", auto_adjust=True, progress=False)
        
        if df.empty:
            print(f"‚ùå [ERREUR] Pas de donn√©es re√ßues pour {ticker}")
            return None
            
        if isinstance(df.columns, pd.MultiIndex):
            df = df.xs(ticker, axis=1, level=1)
        
        # Nettoyage et sauvegarde
        df = df.dropna()
        df.to_csv(file_path)
        print(f"‚úÖ [SUCC√àS] {len(df)} bougies sauvegard√©es dans {file_path}")
        return file_path
        
    except Exception as e:
        print(f"‚ùå [CRASH] Erreur t√©l√©chargement {ticker}: {e}")
        return None

def train_model(ticker, timesteps=TIMESTEPS, current=1, total=1):
    
    print_header(ticker, current, total)
    
    # 1. CACHE DES DONN√âES
    csv_path = download_and_cache_data(ticker)
    if csv_path is None:
        print(f"‚ö†Ô∏è  SKIP : Impossible de charger les donn√©es pour {ticker}")
        return

    # 2. WANDB INIT
    run_name = f"{ticker}_ULTRA_{pd.Timestamp.now().strftime('%Y%m%d_%H%M')}"
    run = wandb.init(
        project=WANDB_CONFIG["project"],
        name=run_name,
        config={
            "ticker": ticker,
            "timesteps": timesteps,
            "n_envs": N_ENVS,
            "batch_size": BATCH_SIZE,
            "device": "cuda" if USE_GPU else "cpu",
            **TRAINING_CONFIG
        },
        sync_tensorboard=True,
        reinit=True
    )
    
    # 3. CR√âATION ENVIRONNEMENT MULTI-PROCESS
    print(f"üî® Cr√©ation du cluster d'environnements ({N_ENVS} workers)...")
    def make_env():
        return TradingEnv(csv_path=csv_path) # Chaque worker lit son CSV localement
    
    env = SubprocVecEnv([make_env for _ in range(N_ENVS)])
    
    # 4. MOD√àLE PPO (CONFIGURATION LOURDE)
    policy_kwargs = dict(
        net_arch=dict(pi=[512, 512, 512], vf=[512, 512, 512]) # Gros cerveau
    )
    
    print("üß† Initialisation du mod√®le PPO (Large Network)...")
    model = PPO(
        "MlpPolicy",
        env,
        verbose=1,
        device="cuda" if USE_GPU else "cpu",
        learning_rate=1e-4,     # Un peu plus lent pour la stabilit√©
        batch_size=BATCH_SIZE,  # Optimis√© pour RTX 3080
        n_steps=N_STEPS,        # Buffer cons√©quent
        n_epochs=10,            # Bien dig√©rer les donn√©es
        ent_coef=0.01,          # Encourager l'exploration
        policy_kwargs=policy_kwargs,
        tensorboard_log=f"{TRAINING_CONFIG.get('tensorboard_dir', 'tensorboard')}/{ticker}"
    )
    
    # 5. CALLBACKS
    checkpoint_callback = CheckpointCallback(
        save_freq=max(100_000 // N_ENVS, 1), # Ajust√© selon n_envs
        save_path=f"models/checkpoints/{ticker}",
        name_prefix=f"{ticker}_model"
    )
    
    wandb_callback = WandbCallback(
        model_save_path=f"models/{ticker}",
        verbose=2,
        gradient_save_freq=1000
    )
    
    # 6. ENTRA√éNEMENT
    start_time = time.time()
    print(f"\nüèÅ D√âBUT DE LA COURSE ({timesteps:,} steps)... Go!")
    
    try:
        model.learn(
            total_timesteps=timesteps,
            callback=[checkpoint_callback, wandb_callback],
            progress_bar=True
        )
    except KeyboardInterrupt:
        print("\nüõë Interruption manuelle ! Sauvegarde d'urgence...")
    
    duration = (time.time() - start_time) / 60
    print(f"\n‚úÖ TRAINING TERMIN√â en {duration:.1f} minutes.")
    
    # 7. SAUVEGARDE
    final_path = f"models/{ticker}_final.zip"
    model.save(final_path)
    print(f"üíæ Mod√®le sauvegard√© sous : {final_path}")
    
    # Nettoyage
    env.close()
    wandb.finish()

if __name__ == "__main__":
    # Liste des tickers (Top Liquidit√©)
    tickers = ["NVDA", "TSLA", "AAPL", "AMD", "MSFT", "AMZN", "GOOGL"]
    
    total_tickers = len(tickers)
    print(f"\nüî• D√âMARRAGE DE LA SESSION D'ENTRA√éNEMENT ({total_tickers} actifs)")
    
    for i, ticker in enumerate(tickers, 1):
        train_model(ticker, current=i, total=total_tickers)
