import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd
import yfinance as yf
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv
from stable_baselines3.common.callbacks import CheckpointCallback
from core.environment import TradingEnv
from config.settings import TRAINING_CONFIG, WANDB_CONFIG, USE_GPU
import wandb
from wandb.integration.sb3 import WandbCallback

def download_and_cache_data(ticker, data_dir="data_cache"):
    """T√©l√©charge et met en cache les donn√©es une seule fois"""
    os.makedirs(data_dir, exist_ok=True)
    file_path = f"{data_dir}/{ticker}.csv"
    
    # V√©rifier si le fichier existe et n'est pas trop vieux (< 7 jours)
    if os.path.exists(file_path):
        file_age = (pd.Timestamp.now() - pd.Timestamp(os.path.getmtime(file_path), unit='s')).days
        if file_age < 7:
            print(f"üìÇ Utilisation du cache local pour {ticker} (age: {file_age} jours)")
            return file_path
    
    # T√©l√©charger les donn√©es
    print(f"üì• T√©l√©chargement des donn√©es pour {ticker} (5 ans, hourly)...")
    try:
        df = yf.download(ticker, period="5y", interval="1h", auto_adjust=True, progress=False)
        
        if df.empty:
            print(f"‚ùå Pas de donn√©es pour {ticker}")
            return None
            
        # Nettoyer si MultiIndex
        if isinstance(df.columns, pd.MultiIndex):
            df = df.xs(ticker, axis=1, level=1)
        
        df.to_csv(file_path)
        print(f"‚úÖ Donn√©es sauvegard√©es : {file_path} ({len(df)} lignes)")
        return file_path
        
    except Exception as e:
        print(f"‚ùå Erreur t√©l√©chargement {ticker}: {e}")
        return None

def train_model(ticker, timesteps=5_000_000):
    """Entra√Æne un mod√®le PPO pour un ticker sp√©cifique"""
    
    print("\n" + "="*70)
    print(f"üéØ TRAINING: {ticker}")
    print("="*70)
    
    # 1. PR√â-CHARGEMENT DES DONN√âES (UNE SEULE FOIS)
    csv_path = download_and_cache_data(ticker)
    if csv_path is None:
        print(f"‚ö†Ô∏è Impossible de charger les donn√©es pour {ticker}, skip.")
        return
    
    # 2. Initialiser W&B
    run = wandb.init(
        project=WANDB_CONFIG["project"],
        name=f"{ticker}_{pd.Timestamp.now().strftime('%Y%m%d_%H%M')}",
        config={
            "ticker": ticker,
            "timesteps": timesteps,
            "algorithm": "PPO",
            "policy": "MlpPolicy",
            **TRAINING_CONFIG
        },
        sync_tensorboard=True,
        monitor_gym=True,
        save_code=True,
        reinit=True
    )
    
    # 3. CONFIGURATION GPU/CPU
    device = "cuda" if USE_GPU else "cpu"
    print(f"üñ•Ô∏è  Device: {device}")
    
    # 4. ENVIRONNEMENTS PARALL√àLES (Exploitation CPU maximale)
    n_envs = 64  # <-- AUGMENT√â √Ä 64 pour utiliser tous tes c≈ìurs
    print(f"üîß Cr√©ation de {n_envs} environnements...")
    
    # Lambda pour cr√©er des environnements qui lisent le M√äME fichier CSV
    def make_env():
        return TradingEnv(csv_path=csv_path)
    
    env = SubprocVecEnv([make_env for _ in range(n_envs)])
    
    # 5. CONFIGURATION R√âSEAU NEURONAL (Plus gros pour GPU)
    policy_kwargs = dict(
        net_arch=dict(
            pi=[512, 512, 512],  # Policy network (actions)
            vf=[512, 512, 512]   # Value network (critique)
        )
    )
    
    print("üß† Cr√©ation du mod√®le PPO...")
    model = PPO(
        "MlpPolicy",
        env,
        verbose=1,
        device=device,
        learning_rate=1e-4,
        
        # PARAM√àTRES OPTIMIS√âS POUR GPU
        batch_size=4096,      # Batch √©norme pour GPU (vs 64 par d√©faut)
        n_steps=2048,         # Steps par env avant update (64 * 2048 = 131k buffer)
        n_epochs=10,          # Passe 10 fois sur les donn√©es
        
        policy_kwargs=policy_kwargs,
        tensorboard_log=f"{TRAINING_CONFIG.get('tensorboard_dir', 'tensorboard')}/{ticker}"
    )
    
    # 6. CALLBACKS
    checkpoint_callback = CheckpointCallback(
        save_freq=100_000,
        save_path=f"models/checkpoints/{ticker}",
        name_prefix=f"{ticker}_model"
    )
    
    wandb_callback = WandbCallback(
        model_save_path=f"models/{ticker}",
        verbose=2
    )
    
    # 7. ENTRA√éNEMENT
    print(f"üöÄ D√©but entra√Ænement ({timesteps:,} timesteps)...")
    model.learn(
        total_timesteps=timesteps,
        callback=[checkpoint_callback, wandb_callback],
        progress_bar=True
    )
    
    # 8. SAUVEGARDE FINALE
    model_path = f"models/{ticker}_final.zip"
    model.save(model_path)
    print(f"üíæ Mod√®le sauvegard√©: {model_path}")
    
    # 9. NETTOYAGE
    env.close()
    wandb.finish()
    
    print(f"‚úÖ Training termin√© pour {ticker}")

if __name__ == "__main__":
    # Liste des tickers √† entra√Æner
    tickers = ["NVDA", "MSFT", "AAPL", "GOOGL", "AMZN", "TSLA", "AMD"]
    
    for i, ticker in enumerate(tickers, 1):
        print(f"\n[{i}/{len(tickers)}] {ticker}")
        train_model(ticker, timesteps=5_000_000)
