# Ploutos Trading V9 (Polars + Shared Memory)

Un projet personnel de trading algorithmique utilisant le Reinforcement Learning. L'idÃ©e : entraÃ®ner un agent Ã  trader de maniÃ¨re autonome sur les marchÃ©s financiers.

> âš ï¸ **Avertissement** : Ce projet est expÃ©rimental et en paper trading. Le trading algorithmique comporte des risques significatifs. Ne jamais utiliser d'argent rÃ©el sans comprendre ces risques.

---

## C'est quoi ?

Ploutos est un bot de trading qui apprend par lui-mÃªme en utilisant l'algorithme PPO (Proximal Policy Optimization). Au lieu de suivre des rÃ¨gles fixes, il observe le marchÃ© et dÃ©veloppe sa propre stratÃ©gie.

**Ce que Ã§a fait :**
- Collecte les donnÃ©es de marchÃ© (via Alpaca)
- Analyse les tendances avec 85+ indicateurs techniques (Moteur Polars ultra-rapide)
- Prend des dÃ©cisions d'achat/vente de maniÃ¨re autonome
- Utilise la Shared Memory pour un entraÃ®nement parallÃ¨le sans surcharger la RAM
- Se rÃ©-entraÃ®ne automatiquement si nÃ©cessaire

---

## Performances actuelles

| MÃ©trique | Valeur |
|----------|--------|
| Sharpe Ratio | ~1.5 |
| Max Drawdown | -12% |
| Win Rate | 55% |
| **Speed (Features)** | **x100 (0.09s/100k bars)** |
| Mode | Paper Trading |

*Ces rÃ©sultats sont en paper trading et ne garantissent rien en conditions rÃ©elles.*

---

## Installation

```bash
# Cloner le repo
git clone https://github.com/Vimif/project_ploutos
cd project_ploutos

# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# Installer les dÃ©pendances (Polars, PyArrow, Torch...)
pip install -e .
```

---

## Workflow d'entraÃ®nement (V9)

Le pipeline V9 utilise le walk-forward training avec support natif pour **Polars** et **Shared Memory**.

### 1. Pipeline High-Performance (RecommandÃ©)

```bash
# Script optimisÃ© pour le hardware (thread pinning, limit open files, auto-scale)
./start_training.sh
```

Ce script configure automatiquement l'environnement (OMP_NUM_THREADS), dÃ©tecte le hardware (GPU/RAM) et lance le pipeline complet avec les paramÃ¨tres optimaux.

### 2. EntraÃ®nement Walk-Forward (sÃ©parÃ©)

```bash
# PPO standard avec Shared Memory (V9)
python training/train.py --config config/config.yaml --auto-scale --shared-memory

# RecurrentPPO avec LSTM
python training/train.py --config config/config.yaml --recurrent --auto-scale --shared-memory

# Ensemble de 3 modÃ¨les
python training/train.py --config config/config.yaml --ensemble 3 --auto-scale --shared-memory
```

### 3. Optimisation des hyperparamÃ¨tres (optionnel)

```bash
# Auto-dÃ©tecte le nombre de jobs parallÃ¨les et n_envs par trial
python scripts/optimize_hyperparams.py --config config/config.yaml --n-trials 50 --auto-scale

# Ou manuellement : 4 trials parallÃ¨les
python scripts/optimize_hyperparams.py --config config/config.yaml --n-trials 50 --n-jobs 4
```

### 4. Tests de robustesse (sÃ©parÃ©)

```bash
# Monte Carlo parallÃ©lisÃ© + stress test
python scripts/robustness_tests.py --model models/<fold>/model.zip --vecnorm models/<fold>/vecnormalize.pkl --all --auto-scale

# Monte Carlo seul
python scripts/robustness_tests.py --model models/<fold>/model.zip --monte-carlo 1000 --auto-scale
```

### 5. Paper trading

```bash
# Lance le paper trading (dÃ©tecte auto V9)
python scripts/paper_trade.py --model models/.../model.zip
```

> **GPU Cloud** : Avec `--auto-scale`, un seul config suffit pour dev et cloud. Voir le [guide RunPod](docs/RUNPOD_GUIDE.md).

---

## Structure du projet

```
project_ploutos/
â”œâ”€â”€ config/             # Configuration
â”‚   â”œâ”€â”€ hardware.py          # Auto-dÃ©tection GPU/CPU/RAM + scaling
â”‚   â””â”€â”€ config.yaml          # Config training standard
â”œâ”€â”€ core/               # Code principal V9
â”‚   â”œâ”€â”€ environment.py       # Environnement V9 (Unified + SharedMem)
â”‚   â”œâ”€â”€ features.py          # Moteur Polars (x100 speed)
â”‚   â”œâ”€â”€ shared_memory_manager.py # Gestionnaire Shared Memory
â”‚   â”œâ”€â”€ data_fetcher.py      # RÃ©cupÃ©ration des donnÃ©es
â”‚   â””â”€â”€ risk_manager.py      # Gestion du risque
â”œâ”€â”€ trading/            # IntÃ©grations broker (eToro, Alpaca)
â”œâ”€â”€ training/           # Module d'entraÃ®nement
â”‚   â””â”€â”€ train.py             # Script Walk-Forward V9
â”œâ”€â”€ scripts/            # CLI (pipeline, optimisation, robustness, paper trade)
â”‚   â”œâ”€â”€ run_pipeline.py      # Pipeline complet trainingâ†’robustness
â”‚   â”œâ”€â”€ paper_trade.py       # Paper Trading V9
â”‚   â””â”€â”€ ...
â”œâ”€â”€ legacy/             # Archives (V6/V7/V8)
â””â”€â”€ docs/               # Documentation
    â”œâ”€â”€ ARCHITECTURE_V9.md   # ğŸ—ï¸ Architecture Technique V9
    â”œâ”€â”€ RELEASE_NOTES_V9.md  # ğŸš€ NouveautÃ©s V9
    â”œâ”€â”€ RUNPOD_GUIDE.md      # Guide dÃ©ploiement Cloud
    â””â”€â”€ ...
```

---

## Configuration

Ã‰dite `config/config.yaml` :

```yaml
training:
  total_timesteps: 10000000  # par fold walk-forward
  n_envs: 16                 # Auto-scalÃ© si --auto-scale
  use_shared_memory: true    # Activer V9 Shared Memory

walk_forward:
  train_years: 1       # DurÃ©e du training par fold
  test_months: 6       # DurÃ©e du test
  step_months: 6       # Pas entre chaque fold

wandb:
  enabled: false       # Activer pour le tracking
```

---

## Monitoring

**Logs** : `logs/train.log`

**Dashboards disponibles** :
- TensorBoard : `tensorboard --logdir models/walk_forward_.../`
- Grafana : `http://localhost:3000` (si configurÃ©)

---

## La roadmap

**Fait :**
- [x] Curriculum Learning (apprentissage progressif)
- [x] CoÃ»ts de transaction rÃ©alistes
- [x] Walk-forward validation (V9)
- [x] Ensemble de modÃ¨les
- [x] DonnÃ©es macro (VIX/TNX/DXY)
- [x] RecurrentPPO (LSTM)
- [x] DÃ©ploiement cloud (RunPod)
- [x] Auto-scaling hardware (GPU/CPU/RAM)
- [x] **"Turbo Init" (Polars Engine x100)**
- [x] **Optimisation RAM (Shared Memory)**
- [x] Protection contre le Data Leakage (Embargo)
- [x] Tests de Robustesse (Monte Carlo + PSR/DSR)

**Prochaines Ã‰tapes :**
- [ ] Tests Unitaires & CI/CD (Pytest 100% coverage)
- [ ] DÃ©tection des rÃ©gimes de marchÃ© (HMM/Clustering)

**Futur :**
- [ ] Architecture Transformer
- [ ] Meta-learning (MAML)

---

## License

MIT

---

*DerniÃ¨re mise Ã  jour : FÃ©vrier 2026 (V9)*
