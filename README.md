# Ploutos Trading

Un projet personnel de trading algorithmique utilisant le Reinforcement Learning. L'idÃ©e : entraÃ®ner un agent Ã  trader de maniÃ¨re autonome sur les marchÃ©s financiers.

> âš ï¸ **Avertissement** : Ce projet est expÃ©rimental et en paper trading. Le trading algorithmique comporte des risques significatifs. Ne jamais utiliser d'argent rÃ©el sans comprendre ces risques.

---

## C'est quoi ?

Ploutos est un bot de trading qui apprend par lui-mÃªme en utilisant l'algorithme PPO (Proximal Policy Optimization). Au lieu de suivre des rÃ¨gles fixes, il observe le marchÃ© et dÃ©veloppe sa propre stratÃ©gie.

**Ce que Ã§a fait :**
- Collecte les donnÃ©es de marchÃ© (via Alpaca)
- Analyse les tendances avec des indicateurs techniques
- Prend des dÃ©cisions d'achat/vente de maniÃ¨re autonome
- DÃ©tecte quand ses performances se dÃ©gradent (drift detection)
- Se rÃ©-entraÃ®ne automatiquement si nÃ©cessaire

---

## Performances actuelles

| MÃ©trique | Valeur |
|----------|--------|
| Sharpe Ratio | ~1.5 |
| Max Drawdown | -12% |
| Win Rate | 55% |
| Mode | Paper Trading |

*Ces rÃ©sultats sont en paper trading et ne garantissent rien en conditions rÃ©elles.*

---

## Installation

```bash
# Cloner le repo
git clone https://github.com/Vimif/project_ploutos
cd project_ploutos

# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# Installer les dÃ©pendances
pip install -e .
```

---

## Workflow d'entraÃ®nement (V8)

Le pipeline optimisÃ© utilise le walk-forward training avec validation glissante.

### 1. Pipeline High-Performance (RecommandÃ©)

```bash
# Script optimisÃ© pour le hardware (thread pinning, limit open files, auto-scale)
./start_training.sh
```

Ce script configure automatiquement l'environnement (OMP_NUM_THREADS), dÃ©tecte le hardware (GPU/RAM) et lance le pipeline complet avec les paramÃ¨tres optimaux (Batch 65k, 256 Envs si possible).

### 2. EntraÃ®nement Walk-Forward (sÃ©parÃ©)

```bash
# PPO standard
python training/train_walk_forward.py --config config/training_config_v8.yaml --auto-scale

# RecurrentPPO avec LSTM
python training/train_walk_forward.py --config config/training_config_v8.yaml --recurrent --auto-scale

# Ensemble de 3 modÃ¨les
python training/train_walk_forward.py --config config/training_config_v8.yaml --ensemble 3 --auto-scale
```

### 3. Optimisation des hyperparamÃ¨tres (optionnel)

```bash
# Auto-dÃ©tecte le nombre de jobs parallÃ¨les et n_envs par trial
python scripts/optimize_hyperparams.py --config config/training_config_v8.yaml --n-trials 50 --auto-scale

# Ou manuellement : 4 trials parallÃ¨les
python scripts/optimize_hyperparams.py --config config/training_config_v8.yaml --n-trials 50 --n-jobs 4
```

### 4. Tests de robustesse (sÃ©parÃ©)

```bash
# Monte Carlo parallÃ©lisÃ© + stress test
python scripts/robustness_tests.py --model models/<fold>/model.zip --vecnorm models/<fold>/vecnormalize.pkl --all --auto-scale

# Monte Carlo seul
python scripts/robustness_tests.py --model models/<fold>/model.zip --monte-carlo 1000 --auto-scale
```

### 5. Paper trading

```bash
python scripts/paper_trade_v7.py
```

> **GPU Cloud** : Avec `--auto-scale`, un seul config suffit pour dev et cloud. Voir le [guide RunPod](docs/RUNPOD_GUIDE.md).

---

## Structure du projet

```
project_ploutos/
â”œâ”€â”€ config/           # Configuration
â”‚   â”œâ”€â”€ hardware.py            # Auto-dÃ©tection GPU/CPU/RAM + scaling
â”‚   â”œâ”€â”€ settings.py            # Chemins, broker, WandB
â”‚   â”œâ”€â”€ training_config_v8.yaml         # Config training standard
â”‚   â””â”€â”€ training_config_v8_cloud.yaml   # Config cloud (override manuel)
â”œâ”€â”€ core/             # Code principal
â”‚   â”œâ”€â”€ universal_environment_v8_lstm.py  # Environnement Gym (V8)
â”‚   â”œâ”€â”€ data_fetcher.py       # RÃ©cupÃ©ration des donnÃ©es (Yahoo Finance)
â”‚   â”œâ”€â”€ macro_data.py         # Indicateurs macro (VIX/TNX/DXY)
â”‚   â”œâ”€â”€ ensemble.py           # Ensemble multi-modÃ¨les
â”‚   â”œâ”€â”€ data_pipeline.py      # Feature engineering
â”‚   â””â”€â”€ risk_manager.py       # Gestion du risque
â”œâ”€â”€ trading/          # IntÃ©grations broker (eToro, Alpaca)
â”œâ”€â”€ training/         # Walk-forward training (V8)
â”œâ”€â”€ scripts/          # CLI (pipeline, optimisation, robustness, paper trade)
â”‚   â”œâ”€â”€ run_pipeline.py       # Pipeline complet trainingâ†’robustness
â”‚   â”œâ”€â”€ optimize_hyperparams.py  # Optuna hyperparameter search
â”‚   â””â”€â”€ robustness_tests.py   # Monte Carlo + stress tests
â””â”€â”€ docs/             # Documentation
    â”œâ”€â”€ AUDIT_TECHNIQUE_V8.md # ğŸ›¡ï¸ Audit Technique & Architecture (Fev 2026)
    â”œâ”€â”€ DEV_KNOWLEDGE.md      # Base de connaissance dÃ©veloppeur
    â””â”€â”€ RUNPOD_GUIDE.md       # Guide dÃ©ploiement Cloud
```

---

## Configuration

Ã‰dite `config/training_config_v8.yaml` :

```yaml
training:
  total_timesteps: 10000000  # par fold walk-forward
  n_envs: 8
  learning_rate: 0.0001

walk_forward:
  train_years: 1       # DurÃ©e du training par fold
  test_months: 6       # DurÃ©e du test
  step_months: 6       # Pas entre chaque fold

wandb:
  enabled: false       # Activer pour le tracking
```

---

## Monitoring

**Logs** : `logs/ploutos_*.log`

**Dashboards disponibles** :
- TensorBoard : `tensorboard --logdir logs/tensorboard`
- Grafana : `http://localhost:3000` (si configurÃ©)

---

## La roadmap

**Fait :**
- [x] Curriculum Learning (apprentissage progressif)
- [x] CoÃ»ts de transaction rÃ©alistes
- [x] Walk-forward validation (V8)
- [x] Ensemble de modÃ¨les
- [x] DonnÃ©es macro (VIX/TNX/DXY)
- [x] RecurrentPPO (LSTM)
- [x] DÃ©ploiement cloud (RunPod)
- [x] Auto-scaling hardware (GPU/CPU/RAM)
- [x] Pipeline orchestrateur (training + robustness)
- [x] "Turbo Init" (Pre-computed Features)
- [x] AmÃ©lioration du systÃ¨me de rÃ©compense (Differential Sharpe Ratio)
- [x] Protection contre le Data Leakage (Embargo)
- [x] Tests de Robustesse (Monte Carlo + PSR/DSR)

**Prochaines Ã‰tapes (V9) :**
- [ ] Tests Unitaires & CI/CD (Pytest)
- [ ] Optimisation RAM (Shared Memory)
- [ ] DÃ©tection des rÃ©gimes de marchÃ© (HMM/Clustering)

**Futur :**
- [ ] Architecture Transformer
- [ ] Meta-learning (MAML)

---

## License

MIT

---

*DerniÃ¨re mise Ã  jour : FÃ©vrier 2026*
